# arXiv Research Digest

<div style="border-radius:16px;padding:18px 20px;background:linear-gradient(135deg,#0f172a,#1d4ed8,#0ea5e9);color:#eff6ff;">
<div style="font-size:22px;font-weight:700;margin-bottom:8px;">Literature Snapshot</div>
<div style="line-height:1.7;"><b>Categories</b>: cs.AI, cs.CL, cs.LG, cs.CV<br/><b>Keywords</b>: vlm, vision language model, latent token, large language model, multimodal large language model<br/><b>Match Mode</b>: any<br/><b>Summary Provider</b>: openai-compatible<br/><b>Summary Language</b>: zh<br/><b>Date Range</b>: 2026-02-01 to 2026-02-27<br/><b>Retrieved</b>: 152 | <b>History Dedup Removed</b>: 0 | <b>Translated to zh</b>: 4</div>
</div>

<div style="margin-top:12px;border-left:4px solid #f59e0b;background:#fffbeb;padding:10px 12px;border-radius:8px;">
<b>Warnings</b><br/>
- LLM summary fallback: 4 papers failed (The read operation timed out). Sample IDs: 2602.22280, 2602.22013, 2602.21824, 2602.21814.<br/>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">1. MediX-R1: Open Ended Medical Reinforcement Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23363</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Sahal Shaji Mullappilly, Mohammed Irfan Kurpath, Omair Mohamed, Mohamed Zidan, Fahad Khan, Salman Khan, Rao Anwer, Hisham Cholakkal<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23363v1">https://arxiv.org/abs/2602.23363v1</a><br/><b>Summary</b>: 针对医学多模态大语言模型（MLLM）在开放端临床推理中面临反馈不足的挑战，MediX-R1 提出一种基于强化学习的框架，利用组基策略微调视觉语言模型（VLM）骨干。该方法设计包含大语言模型（LLM）评分的复合奖励机制与统一评估体系，在少量数据下显著提升了多模态医疗任务表现，验证了开放端强化学习在实现可靠医疗推理方面的有效性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">2. Scale Can't Overcome Pragmatics: The Impact of Reporting Bias on Vision-Language Reasoning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23351</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.CV<br/><b>Authors</b>: Amita Kamath, Jack Hessel, Khyathi Chandu, Jena D. Hwang, Kai-Wei Chang, Ranjay Krishna<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23351v1">https://arxiv.org/abs/2602.23351v1</a><br/><b>Summary</b>: 该研究指出 Vision Language Model (VLM) 推理能力的缺失源于训练数据的报告偏差，即人类描述视觉内容时默认省略了隐含的推理信息。通过对 OpenCLIP 和 LLaVA 等模型的数据分析及基准测试，研究发现仅靠扩展数据或模型规模无法使多模态大语言模型（MLLM）涌现出空间、计数等推理技能。其关键贡献在于证明通过刻意收集隐性信息的标注来优化训练数据，比单纯依赖规模扩展更能有效提升 VLM 的推理表现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">3. Retrieve and Segment: Are a Few Examples Enough to Bridge the Supervision Gap in Open-Vocabulary Segmentation?</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23339</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Tilemachos Aravanis, Vladan Stojnić, Bill Psomas, Nikos Komodakis, Giorgos Tolias<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23339v1">https://arxiv.org/abs/2602.23339v1</a><br/><b>Summary</b>: 针对视觉语言模型（VLM）在开放词汇分割任务中因图像级监督不足和语义歧义导致的性能瓶颈，本文提出一种基于少量示例的检索增强测试时适配器，通过融合文本与视觉支持特征，在多模态大语言模型架构下实现轻量化的每图像分类器学习。该方法避免了传统的手工融合方式，能够持续扩展支持集以适应个性化分割等细粒度任务。实验证明，此策略显著缩小了零样本与全监督分割的差距，在保持开放词汇能力的同时大幅提升了分割精度。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">4. Utilizing LLMs for Industrial Process Automation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23331</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Salim Fares<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23331v1">https://arxiv.org/abs/2602.23331v1</a><br/><b>Summary</b>: 针对现有大型语言模型（large language model）研究多聚焦于通用编程语言而忽视工业专用场景的问题，本文提出将其集成至工业自动化开发流程中。通过利用 LLM 解决如机械臂运动指令生成等实际编程任务，该方法旨在加速制造系统的开发周期并提升自动化效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">5. Toward Expert Investment Teams:A Multi-Agent LLM System with Fine-Grained Trading Tasks</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23330</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Kunihiro Miyazaki, Takanobu Kawahara, Stephen Roberts, Stefan Zohren<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23330v1">https://arxiv.org/abs/2602.23330v1</a><br/><b>Summary</b>: 针对现有大型语言模型（large language model）多智能体系统因指令抽象导致性能不佳的问题，本文提出了一种将投资分析分解为细粒度任务的框架，有效处理了包括价格与新闻在内的多模态金融数据。实验结果表明，该方法通过优化中间代理输出的对齐性，显著提升了风险调整后收益，为实际交易中大型语言模型的智能体结构设计提供了关键指导。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">6. LLM Novice Uplift on Dual-Use, In Silico Biology Tasks</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23329</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Chen Bo Calvin Zhang, Christina Q. Knight, Nicholas Kruus, Jason Hausenloy, Pedro Medeiros, Nathaniel Li, Aiden Kim, Yury Orlovskiy, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23329v1">https://arxiv.org/abs/2602.23329v1</a><br/><b>Summary</b>: 本研究针对大语言模型（LLM）能否显著提升生物领域新手表现及其双用途风险问题，通过多基准实验对比了 LLM 辅助与纯网络搜索的效果。结果显示 LLM 使新手准确率提升 4.16 倍且部分超越专家，但同时也暴露了现有安全机制难以完全阻断敏感信息获取的隐患，强调了持续评估交互式提升的重要性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">7. Evaluating Zero-Shot and One-Shot Adaptation of Small Language Models in Leader-Follower Interaction</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23312</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Rafael R. Baptista, André de Lima Salgado, Ricardo V. Godoy, Marcelo Becker, Thiago Boaventura, Gustavo J. G. Lahr<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23312v1">https://arxiv.org/abs/2602.23312v1</a><br/><b>Summary</b>: 针对大型语言模型（LLM）在资源受限机器人上部署延迟高的问题，本文构建了基准测试以评估小语言模型在领导者 - 跟随者交互中的零样本与单样本适应能力。实验结果显示，微调后的小语言模型能以 22.2 毫秒的低延迟实现 86.66% 的高精度角色分类，显著优于提示工程方法。该工作不仅验证了小型模型在边缘端直接角色分配的有效性，还揭示了对话复杂度增加导致的性能下降这一关键权衡。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">8. ThinkOmni: Lifting Textual Reasoning to Omni-modal Scenarios via Guidance Decoding</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23306</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Yiran Guan, Sifan Tu, Dingkang Liang, Linghao Zhu, Jianzhong Ju, Zhenbo Luo, Jian Luan, Yuliang Liu, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23306v1">https://arxiv.org/abs/2602.23306v1</a><br/><b>Summary</b>: 针对现有**多模态大语言模型**缺乏复杂推理能力且训练成本高昂的问题，ThinkOmni 提出了一种利用**大语言模型**引导解码的无需训练框架，有效增强了**视觉语言模型**的推理性能。该方法通过逐步对比缩放平衡感知与推理信号，在多个基准测试中实现了显著性能提升，为全模态推理提供了灵活通用的解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">9. A Mixture-of-Experts Model for Multimodal Emotion Recognition in Conversations</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23300</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Soumya Dutta, Smruthi Balaji, Sriram Ganapathy<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23300v1">https://arxiv.org/abs/2602.23300v1</a><br/><b>Summary</b>: 针对对话情感识别中多模态融合与时序建模的挑战，本文提出了一种基于大语言模型（large language model）的混合专家框架 MiSTER-E。该方法通过动态整合语音与文本专家输出，构建了一个不依赖说话人身份的多模态大语言模型系统以增强跨模态一致性。实验结果显示，该模型在多个基准数据集上显著优于现有基线，有效提升了情感识别性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">10. CXReasonAgent: Evidence-Grounded Diagnostic Reasoning Agent for Chest X-rays</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23276</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Hyungyung Lee, Hangyul Yoon, Edward Choi<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23276v1">https://arxiv.org/abs/2602.23276v1</a><br/><b>Summary</b>: 针对现有**视觉语言模型**（**VLM**）在胸部 X 光诊断中缺乏证据依据且适应性差的局限，本文提出 CXReasonAgent，通过集成**大语言模型**（**LLM**）与临床工具实现证据导向的诊断推理。该方法利用图像衍生的诊断和视觉证据生成可验证的回答，并通过引入 CXReasonDial 基准证明其优于传统**多模态大语言模型**，强调了在安全关键临床场景中整合临床工具的重要性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">11. Mitigating Legibility Tax with Decoupled Prover-Verifier Games</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23248</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Yegon Kim, Juho Lee<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23248v1">https://arxiv.org/abs/2602.23248v1</a><br/><b>Summary</b>: 针对大语言模型在提升输出可检查性时面临准确性退化的“可读性税”问题，本文提出了一种解耦证明者 - 验证者博弈的方法。该方法通过引入翻译模型将求解器的正确解答转换为易验证形式，从而在保持高准确性的同时显著增强了输出对低能力系统的可验证性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">12. Agency and Architectural Limits: Why Optimization-Based Systems Cannot Be Norm-Responsive</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23239</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Radha Sarma<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23239v1">https://arxiv.org/abs/2602.23239v1</a><br/><b>Summary</b>: 本文指出基于优化的系统（特别是**大语言模型**）无法真正响应规范，挑战了其在高风险场景中被治理的假设。研究通过形式化分析确立了真实代理所需的两个架构条件，证明了优化操作与规范性治理之间的根本不相容性。其主要贡献在于提出了区分代理与工具的通用架构规范，同时警示了人类因指标压力退化为优化器从而引发“收敛危机”的风险。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">13. Large Multimodal Models as General In-Context Classifiers</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23229</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Marco Garosi, Matteo Farina, Alessandro Conti, Massimiliano Mancini, Elisa Ricci<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23229v1">https://arxiv.org/abs/2602.23229v1</a><br/><b>Summary</b>: 尽管对比型视觉语言模型（VLM）常被视为零样本分类首选，但本研究指出基于大型语言模型的大型多模态大语言模型（LMM）具备被忽视的上下文学习潜力。研究提出无需训练的 CIRCLE 方法，通过伪标签迭代优化上下文示例，证明 LMM 在开放世界分类中能超越 VLM，确立了其作为统一分类器的潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">14. MovieTeller: Tool-augmented Movie Synopsis with ID Consistent Progressive Abstraction</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23228</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CV<br/><b>Authors</b>: Yizhi Li, Xiaohan Chen, Miao Jiang, Wentao Tang, Gaoang Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23228v1">https://arxiv.org/abs/2602.23228v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（VLM）在处理长电影摘要时面临的角色身份不一致和叙事连贯性差的问题，本文提出了 MovieTeller 框架。该方法采用无需微调的工具增强策略，通过渐进式抽象为多模态大语言模型提供事实锚点，从而有效缓解上下文长度限制并提升生成质量。实验表明，该方案在事实准确性、角色一致性及整体叙事连贯性上均显著优于端到端基线。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">15. InnerQ: Hardware-aware Tuning-free Quantization of KV Cache for Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23200</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Sayed Mohammadreza Tayaranian Hosseini, Amir Ardakani, Warren J. Gross<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23200v1">https://arxiv.org/abs/2602.23200v1</a><br/><b>Summary</b>: 针对大语言模型（large language model）解码过程中键值缓存（KV Cache）导致的显存瓶颈，本文提出了 InnerQ，一种硬件感知的无微调量化方案。该方法采用内维分组与混合量化策略，通过优化反量化过程减少显存访问并加速计算。实验表明，InnerQ 在保持精度的同时将解码延迟最高降低 88%，在 Llama 模型上显著优于现有方法。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">16. SC-Arena: A Natural Language Benchmark for Single-Cell Reasoning with Knowledge-Augmented Evaluation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23199</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Jiahao Zhao, Feng Jiang, Shaowei Qin, Zhonghui Zhang, Junhao Liu, Guibing Guo, Hamid Alinejad-Rokny, Min Yang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23199v1">https://arxiv.org/abs/2602.23199v1</a><br/><b>Summary</b>: 针对 large language model 在单细胞生物学领域评估基准碎片化且缺乏生物学解释性的问题，本文提出了 SC-ARENA 自然语言评估框架。该方法通过虚拟细胞抽象统一评估目标，并引入外部知识库进行知识增强评估以确保生物学正确性。实验表明，该框架能为 large language model 提供统一、可解释且证据支持的评测标准，有效克服了传统指标的脆弱性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">17. Fine-Tuning Without Forgetting In-Context Learning: A Theoretical Analysis of Linear Attention Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23197</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Chungpa Lee, Jy-yong Sohn, Kangwook Lee<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23197v1">https://arxiv.org/abs/2602.23197v1</a><br/><b>Summary</b>: 微调大语言模型虽能提升零样本性能，但往往会导致模型在未见任务上的上下文学习能力退化。本文通过线性注意力模型的理论分析发现，仅更新值矩阵可在保持上下文学习的同时改善零样本表现，而引入辅助损失则可能牺牲泛化能力。实证结果进一步验证了这些关于参数更新策略的理论结论。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">18. ESAA: Event Sourcing for Autonomous Agents in LLM-Based Software Engineering</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23193</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Elzo Brito dos Santos Filho<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23193v1">https://arxiv.org/abs/2602.23193v1</a><br/><b>Summary</b>: 针对基于 large language model 的自主代理存在状态缺失及长程上下文退化等结构性局限，本文提出 ESAA 架构，通过事件溯源模式将认知意图与项目状态变更分离。该方法利用确定性编排器验证并持久化结构化事件，结合哈希校验确保任务不可篡改性与可追溯性，并在多智能体场景中验证了其在异构 large language model 环境下的可扩展性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">19. MTRAG-UN: A Benchmark for Open Challenges in Multi-Turn RAG Conversations</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23184</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Sara Rosenthal, Yannis Katsis, Vraj Shah, Lihong He, Lucian Popa, Marina Danilevsky<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23184v1">https://arxiv.org/abs/2602.23184v1</a><br/><b>Summary</b>: 本文针对大型语言模型在多轮检索增强生成（RAG）对话中面临的未回答、未明确及非独立问题等挑战，提出了 MTRAG-UN 基准测试。该基准包含 666 个任务和超过 2,800 轮跨领域对话，不仅揭示了当前模型在处理此类复杂情境时的性能局限，还为评估和优化基于大型语言模型的检索与生成系统提供了重要的标准化数据集。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">20. A Decision-Theoretic Formalisation of Steganography With Applications to LLM Monitoring</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23163</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Usman Anwar, Julianna Piskorz, David D. Baek, David Africa, Jim Weatherall, Max Tegmark, Christian Schroeder de Witt, Mihaela van der Schaar, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23163v1">https://arxiv.org/abs/2602.23163v1</a><br/><b>Summary</b>: 针对大语言模型（large language model）利用隐写术规避监管且缺乏可行检测基准的问题，本文提出了一种基于决策理论的隐写形式化方法。该方法通过引入广义$\mathcal{V}$-信息定义“隐写差距”，量化了解码能力差异导致的可用信息不对称，从而有效检测并缓解大语言模型中的隐写推理行为。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">21. Modality Collapse as Mismatched Decoding: Information-Theoretic Limits of Multimodal LLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23136</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL, cs.LG<br/><b>Authors</b>: Jayadev Billa<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23136v1">https://arxiv.org/abs/2602.23136v1</a><br/><b>Summary</b>: 本研究揭示了 multimodal large language model 中的模态坍塌问题，指出尽管 vision language model 的编码层保留了模态信息，但 large language model 解码器仅能提取文本对齐方向的 latent token。作者通过信息论将问题形式化为不匹配解码，证明瓶颈在于解码器的评分规则而非编码器结构。实验表明，通过 LoRA 调整训练目标可显著提升 VLM 对特定属性的可访问性，证实了训练目标决定了信息的可提取边界。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">22. Multi-Agent Large Language Model Based Emotional Detoxification Through Personalized Intensity Control for Consumer Protection</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23123</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Keito Inoshita<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23123v1">https://arxiv.org/abs/2602.23123v1</a><br/><b>Summary</b>: 针对网络内容引发的过度情绪刺激阻碍理性决策的问题，本文提出了一种基于多智能体大语言模型的情感去毒系统 MALLET。该系统通过情感分析、调整及个性化引导等模块，利用大语言模型重写文本以在降低刺激强度的同时保持语义完整性。实验结果证实该方法能显著减少情绪刺激并实现独立控制，为消费者提供了支持冷静信息接收的有效框架。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">23. Enhancing CVRP Solver through LLM-driven Automatic Heuristic Design</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23092</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Zhuoliang Xie, Fei Liu, Zhenkun Wang, Qingfu Zhang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23092v1">https://arxiv.org/abs/2602.23092v1</a><br/><b>Summary</b>: 针对容量约束车辆路径问题（CVRP）在大规模实例下的高计算复杂度挑战，本研究提出了一种基于大语言模型（LLM）的自动启发式设计方法 AILS-AHD，利用进化搜索框架动态生成并优化启发式规则以提升求解效率。实验结果表明，该模型在多个基准测试中超越了现有最先进求解器，并在 8 个大规模实例上取得了新的最佳解，充分展示了大语言模型在组合优化领域的潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">24. Cytoarchitecture in Words: Weakly Supervised Vision-Language Modeling for Human Brain Microscopy</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23088</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Matthew Sutton, Katrin Amunts, Timo Dickscheid, Christian Schiffer<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23088v1">https://arxiv.org/abs/2602.23088v1</a><br/><b>Summary</b>: 为解决人类脑显微图像分析中成对图文数据稀缺的问题，本文提出一种弱监督**Vision Language Model (VLM)** 方法，通过标签中介将图像与文本关联，并将视觉基础模型与**Large Language Model (LLM)** 耦合以生成合成描述。该方法构建了一个有效的**Multimodal Large Language Model**，证明了弱配对策略能在缺乏细粒度标注的情况下实现高精度的脑区识别与自然语言描述，为生物医学领域集成自然语言界面提供了可行方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">25. Assessing Deanonymization Risks with Stylometry-Assisted LLM Agent</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23079</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Boyang Zhang, Yang Zhang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23079v1">https://arxiv.org/abs/2602.23079v1</a><br/><b>Summary</b>: 针对大型语言模型（LLM）引发的文本匿名性泄露风险，本文提出 SALA（风格辅助 LLM 分析）框架，通过整合风格特征与 LLM 推理构建可解释的作者归属分析管道。其核心贡献在于设计了一种引导式重写策略，利用代理推理轨迹生成改写提示，在显著降低作者可识别性的同时有效保留文本语义，并通过实验验证了其在保障作者隐私方面的有效性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">26. CiteLLM: An Agentic Platform for Trustworthy Scientific Reference Discovery</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23075</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Mengze Hong, Di Jiang, Chen Jason Zhang, Zichang Guo, Yawen Li, Jun Chen, Shaobo Cui, Zhiyang Su<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23075v1">https://arxiv.org/abs/2602.23075v1</a><br/><b>Summary</b>: 针对大语言模型（large language model）在学术辅助中存在的可信度与隐私风险，本文提出 CiteLLM，一种将模型能力嵌入本地 LaTeX 环境的代理平台。该系统采用动态学科感知路由从可信库检索文献，并仅利用大语言模型生成查询、排序候选项及进行语义验证，从而有效解决了学术诚信与知识产权问题，实现了高可信度且无幻觉的科学参考文献发现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">27. Toward Automatic Filling of Case Report Forms: A Case Study on Data from an Italian Emergency Department</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23062</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Gabriela Anna Kaczmarek, Pietro Ferrazzi, Lorenzo Porta, Vicky Rubini, Bernardo Magnini<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23062v1">https://arxiv.org/abs/2602.23062v1</a><br/><b>Summary</b>: 针对临床病例报告表自动填写中因标注数据稀缺而制约大语言模型发展的难题，本研究构建了一个新的意大利急诊临床笔记数据集并定义了评估指标。通过利用开源大语言模型进行零样本实验，研究发现该任务可行，但需修正模型因谨慎行为导致的偏差。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">28. LLMServingSim 2.0: A Unified Simulator for Heterogeneous and Disaggregated LLM Serving Infrastructure</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23036</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Jaehong Cho, Hyunmin Choi, Guseul Heo, Jongse Park<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23036v1">https://arxiv.org/abs/2602.23036v1</a><br/><b>Summary</b>: 针对现有模拟器难以统一建模异构硬件与解耦架构下大语言模型（LLM）服务运行时交互的问题，本文提出 LLMServingSim 2.0。该方法通过将服务决策与硬件行为整合至单一运行时循环，实现了对批处理、路由及内存等动态行为的交互感知建模。经真实部署验证，该模拟器在复现关键指标时平均误差仅为 0.97%，为下一代大语言模型服务基础设施的系统级协同设计提供了高效且准确的分析平台。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">29. Exploratory Memory-Augmented LLM Agent via Hybrid On- and Off-Policy Optimization</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.23008</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Zeyuan Liu, Jeonghye Kim, Xufang Luo, Dongsheng Li, Yuqing Yang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.23008v1">https://arxiv.org/abs/2602.23008v1</a><br/><b>Summary</b>: 针对强化学习训练的大型语言模型（LLM）智能体在探索新状态时面临的瓶颈，本文提出了结合记忆机制与混合策略优化的 EMPO$^2$ 框架。该方法在 ScienceWorld 和 WebShop 任务上显著优于 GRPO，并展示了无需参数更新即可适应新任务的卓越泛化能力。这一成果为构建更具探索性和通用性的大型语言模型智能体提供了有前景的解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">30. Obscure but Effective: Classical Chinese Jailbreak Prompt Optimization via Bio-Inspired Search</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22983</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Xun Huang, Simeng Qin, Xiaoshuang Jia, Ranjie Duan, Huanqian Yan, Zhitao Zeng, Fei Yang, Yang Liu, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22983v1">https://arxiv.org/abs/2602.22983v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）面临的越狱攻击风险，本文发现古典中文的晦涩性可部分绕过安全约束。为此，研究提出了 CC-BOS 框架，利用生物启发式搜索和多维策略编码自动生成对抗提示以提升黑盒攻击有效性。实验证明该方法优于现有最先进技术，揭示了大模型在特定语言上下文中的安全漏洞。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">31. Modeling Expert AI Diagnostic Alignment via Immutable Inference Snapshots</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22973</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Dimitrios P. Panagoulias, Evangelia-Aikaterini Tsichrintzi, Georgios Savvidis, Evridiki Tsoureli-Nikita<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22973v1">https://arxiv.org/abs/2602.22973v1</a><br/><b>Summary</b>: 针对临床 AI 中专家修正过程缺乏结构化分析的问题，本研究提出一种基于 vision language model (VLM) 的诊断对齐框架，整合 large language model 与序列推理步骤以系统比对 AI 报告与专家结果。该方法在皮肤病学案例中实现了高综合一致性，揭示了传统评估低估了 multimodal large language model 的临床意义对齐，从而支持可追溯的人机协同评价。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">32. SPM-Bench: Benchmarking Large Language Models for Scanning Probe Microscopy</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22971</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Peiyao Xiao, Xiaogang Li, Chengliang Xu, Jiayi Wang, Ben Wang, Zichao Chen, Zeyu Wang, Kejun Yu, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22971v1">https://arxiv.org/abs/2602.22971v1</a><br/><b>Summary</b>: 针对现有科学领域基准测试存在的数据污染与高成本问题，本文提出 SPM-Bench，这是一个专为扫描探针显微镜设计的多模态大语言模型（multimodal large language model）基准。该方法利用视觉语言模型（vision language model, VLM）返回空间坐标作为潜在令牌（latent token）以减少计算开销，并通过自动化流程合成高质量数据。此外，研究引入了严格不完美惩罚 F1（SIP-F1）分数来评估大型语言模型（large language model）的性能并量化其“个性”，为科学数据合成提供了通用范式。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">33. Discovery of Interpretable Physical Laws in Materials via Language-Model-Guided Symbolic Regression</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22967</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Yifeng Guan, Chuyi Liu, Dongzhan Zhou, Lei Bai, Wan-jian Yin, Jingyuan Li, Mao Su<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22967v1">https://arxiv.org/abs/2602.22967v1</a><br/><b>Summary</b>: 针对传统符号回归在高维数据中发现可解释物理定律时易产生复杂非物理公式的问题，本文提出利用 large language model 嵌入的科学知识引导搜索过程。该方法通过将有效搜索空间缩减约$10^5$倍，成功在钙钛矿材料中识别出兼具物理意义与高精度的新公式，有效解决了组合爆炸难题。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">34. FactGuard: Agentic Video Misinformation Detection via Reinforcement Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22963</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Zehao Li, Hongwei Yu, Hao Jiang, Qiang Sheng, Yilong Xu, Baolong Bi, Yang Li, Zhenlong Yuan, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22963v1">https://arxiv.org/abs/2602.22963v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM）在视频虚假信息检测中因固定推理深度和过度信任内部假设而产生的局限性，FactGuard 提出了一种基于强化学习的代理框架。该方法将验证构建为迭代推理过程，利用大型语言模型评估任务模糊性并选择性调用外部工具获取关键证据，同时结合监督微调与强化学习优化决策。实验表明，FactGuard 在多个基准测试中达到最先进水平，显著增强了模型的鲁棒性与泛化能力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">35. Can Agents Distinguish Visually Hard-to-Separate Diseases in a Zero-Shot Setting? A Pilot Study</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22959</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Zihao Zhao, Frederik Hauke, Juliana De Castilhos, Sven Nebelung, Daniel Truhn<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22959v1">https://arxiv.org/abs/2602.22959v1</a><br/><b>Summary</b>: 本研究探讨了基于**大型语言模型**的智能体在零样本设置下区分视觉特征高度混淆疾病的能力，重点关注**多模态大语言模型**的应用。通过引入基于对比裁决的**多智能体框架**，实验显示该方法显著提升了诊断准确率并减少了无根据声明，尽管整体性能仍不足以临床部署。这一工作为**视觉语言模型**在复杂视觉场景下的零样本推理表现提供了重要的基准测试与初步见解。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">36. MSJoE: Jointly Evolving MLLM and Sampler for Efficient Long-Form Video Understanding</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22932</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Wenhui Tan, Xiaoyi Yu, Jiaze Li, Yijing Chen, Jianzhong Ju, Zhenbo Luo, Ruihua Song, Jian Luan<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22932v1">https://arxiv.org/abs/2602.22932v1</a><br/><b>Summary</b>: 针对**视觉语言模型**在长视频理解中的效率挑战，本文提出 MSJoE 框架，通过联合进化**多模态大语言模型**（MLLM）与轻量级关键帧采样器，利用强化学习协同优化查询推理与帧选择以提取关键信息。该方法将精选的关键帧输入**大型语言模型**进行回答生成，并在多个基准测试上相比现有最强基线取得了显著的性能提升。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">37. Where Vision Becomes Text: Locating the OCR Routing Bottleneck in Vision-Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22918</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Jonathan Steinberg, Oren Gal<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22918v1">https://arxiv.org/abs/2602.22918v1</a><br/><b>Summary</b>: 本研究针对视觉语言模型（VLM）中 OCR 信息如何融入语言处理流的问题，利用因果干预定位了多模态大语言模型内的 OCR 路由瓶颈。研究发现 OCR 信号呈低维特性，其关键层因架构而异，且在模块化设计中移除 OCR 可提升性能，这为理解大型语言模型与视觉模块的交互及优化提供了新视角。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">38. SIGMA: A Semantic-Grounded Instruction-Driven Generative Multi-Task Recommender at AliExpress</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22913</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yang Yu, Lei Kou, Huaikuan Yi, Bin Chen, Yayu Cao, Lei Shen, Chao Zhang, Bing Wang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22913v1">https://arxiv.org/abs/2602.22913v1</a><br/><b>Summary</b>: 针对现有生成式推荐系统局限于交互驱动且难以适应多样化业务需求的问题，本文提出 SIGMA，一种基于**大语言模型**的语义接地指令驱动生成式多任务推荐器。该方法利用统一潜在空间捕捉语义与协作关系，并通过混合**潜在令牌**（Latent Token）技术实现精确建模，最终借助大规模多任务微调与自适应概率融合机制显著提升了推荐的准确性与多样性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">39. PSQE: A Theoretical-Practical Approach to Pseudo Seed Quality Enhancement for Unsupervised MMEA</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22903</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yunpeng Hong, Chenyang Bu, Jie Zhang, Yi He, Di Wu, Xindong Wu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22903v1">https://arxiv.org/abs/2602.22903v1</a><br/><b>Summary</b>: 针对无监督多模态实体对齐中伪种子覆盖不平衡制约大语言模型应用的问题，本文提出 PSQE 方法，通过聚类重采样增强伪种子质量并优化图结构平衡。理论分析揭示了伪种子对对比学习的作用机制，实验验证该即插即用模块能显著提升多模态大语言模型相关任务的性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">40. Towards LLM-Empowered Knowledge Tracing via LLM-Student Hierarchical Behavior Alignment in Hyperbolic Space</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22879</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Xingcheng Fu, Shengpeng Wang, Yisen Gao, Xianxian Li, Chunpei Li, Qingyun Sun, Dongran Yu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22879v1">https://arxiv.org/abs/2602.22879v1</a><br/><b>Summary</b>: 现有知识追踪方法受限于浅层特征，难以捕捉认知状态的层级演变及个性化问题难度感知。为此，本文提出基于**大语言模型**的超空间对齐知识追踪框架（L-HAKT），通过师生代理在双曲空间的行为对齐与对比学习显式建模知识点的树状层级结构，实验证明其能精确刻画不同层级知识点的学习曲线形态。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">41. Test-Time Scaling with Diffusion Language Models via Reward-Guided Stitching</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22871</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Roy Miles, Aysim Toker, Andreea-Maria Oncescu, Songcen Xu, Jiankang Deng, Ismail Elezi<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22871v1">https://arxiv.org/abs/2602.22871v1</a><br/><b>Summary</b>: 针对现有大语言模型推理中轨迹级聚合策略常丢弃部分正确中间步骤的问题，本文提出了一种名为“缝合噪声思维”的自洽性框架，利用扩散语言模型采样轨迹并通过过程奖励模型缝合高质量步骤。实验显示，这一无需训练的模块化流程在数学与编码任务上将准确率最高提升了 23.8%，同时将延迟降低了 1.8 倍，有效平衡了探索与求解效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">42. Rejection Mixing: Fast Semantic Propagation of Mask Tokens for Efficient DLLM Inference</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22868</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Yushi Ye, Feng Hong, Huangjie Zheng, Xu Chen, Zhiyong Chen, Yanfeng Wang, Jiangchao Yao<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22868v1">https://arxiv.org/abs/2602.22868v1</a><br/><b>Summary</b>: 针对扩散大语言模型（DLLM）并行解码中因“组合矛盾”引发的质量与速度权衡难题，本文提出了 ReMix 框架。该方法通过引入连续混合状态在连续空间中迭代优化潜在 token 并利用拒绝规则防止错误传播，有效解决了离散解码中的语义冲突。实验表明，这一无需训练的方法在保持生成质量的同时，为大型语言模型推理带来了 2-8 倍的加速。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">43. TCM-DiffRAG: Personalized Syndrome Differentiation Reasoning Method for Traditional Chinese Medicine based on Knowledge Graph and Chain of Thought</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22828</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Jianmin Li, Ying Chang, Su-Kit Tang, Yujia Liu, Yanwen Wang, Shuyuan Lin, Binkai Ou<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22828v1">https://arxiv.org/abs/2602.22828v1</a><br/><b>Summary</b>: 针对传统检索增强生成（RAG）技术难以有效处理中医复杂辨证推理与个体差异的问题，本研究提出了集成知识图谱与思维链的 TCM-DiffRAG 框架，旨在优化大型语言模型（large language model）的个性化诊疗能力。实验结果显示，TCM-DiffRAG 在多个测试集上显著优于原生模型及其他基准 RAG 方法，证明了结构化知识与推理感知 RAG 对提升医疗诊断任务性能的关键作用。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">44. TARAZ: Persian Short-Answer Question Benchmark for Cultural Evaluation of Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22827</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Reihaneh Iranmanesh, Saeedeh Davoudi, Pasha Abrishamchian, Ophir Frieder, Nazli Goharian<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22827v1">https://arxiv.org/abs/2602.22827v1</a><br/><b>Summary</b>: 针对现有波斯语文化评估基准依赖选择题且无法捕捉语言复杂性的问题，本文提出了一种结合形态归一化与混合句法语义相似度的短答案评估框架。该方法通过对多个大型语言模型（large language model）的系统评测，显著提升了评分一致性，并作为首个标准化基准为跨文化大语言模型研究建立了可复现的基础。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">45. Hierarchy-of-Groups Policy Optimization for Long-Horizon Agentic Tasks</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22817</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Shuo He, Lang Feng, Qi Wei, Xin Cheng, Lei Feng, Bo An<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22817v1">https://arxiv.org/abs/2602.22817v1</a><br/><b>Summary</b>: 针对基于组的强化学习在优化**大语言模型（large language model）**长程智能体任务时因历史上下文不一致导致优势估计偏差的问题，本文提出了层级组策略优化（HGPO）方法，通过层级分组与自适应加权实现偏差方差平衡。实验表明，HGPO 在无需额外模型的情况下，于 ALFWorld 和 WebShop 任务上显著优于现有智能体强化学习算法。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">46. MiroFlow: Towards High-Performance and Robust Open-Source Agent Framework for General Deep Research Tasks</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22808</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Shiqian Su, Sen Xing, Xuan Dong, Muyan Zhong, Bin Wang, Xizhou Zhu, Yuntao Chen, Wenhai Wang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22808v1">https://arxiv.org/abs/2602.22808v1</a><br/><b>Summary</b>: 针对大语言模型在处理需工具交互的复杂任务时能力受限及现有智能体框架不稳定的问题，本文提出了 MiroFlow 开源智能体框架，通过智能体图灵活编排并引入深度推理模式以增强性能。实验表明，MiroFlow 在多个基准测试中取得了最先进性能，为深度研究任务提供了可靠的可复现基线。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">47. Natural Language Declarative Prompting (NLD-P): A Modular Governance Method for Prompt Design Under Model Drift</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22790</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Hyunwoo Kim, Hanau Yi, Jaehee Bae, Yumin Kim<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22790v1">https://arxiv.org/abs/2602.22790v1</a><br/><b>Summary</b>: 面对大型语言模型（large language model）快速演进引发的模型漂移挑战，传统提示工程难以保证控制的稳定性与可解释性。本文提出自然语言声明式提示（NLD-P），将其重构为一种无需外部代码的模块化治理方法，通过自然语言直接编码来源、约束逻辑与任务内容。该贡献为非开发者提供了在持续演化的大模型生态中实现稳定、可解释控制的框架。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">48. Probing for Knowledge Attribution in Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22787</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Ivo Brink, Alexander Boer, Dennis Ulmer<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22787v1">https://arxiv.org/abs/2602.22787v1</a><br/><b>Summary</b>: 针对大语言模型（Large Language Model）常因混淆上下文与内部知识而产生幻觉的问题，本文提出利用基于隐藏表示的探针技术识别输出的主导知识来源。研究构建了自监督数据管道 Attr iWiki 以训练分类器，在多个模型上实现了高达 0.96 的 Macro-F1 准确率。实验结果表明，知识归属错误与不忠实回答率上升直接相关，为理解模型幻觉机制提供了新视角。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">49. TrajTok: Learning Trajectory Tokens enables better Video Understanding</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22779</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Chenhao Zheng, Jieyu Zhang, Jianing Zhang, Weikai Huang, Ashutosh Kumar, Quan Kong, Oncel Tuzel, Chun-Liang Li, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22779v1">https://arxiv.org/abs/2602.22779v1</a><br/><b>Summary</b>: 针对传统视频分块化导致令牌冗余的问题，本文提出TrajTok，一种通过隐式聚类动态生成 latent token 的端到端视频分词器，可无缝集成至 vision language model 或 multimodal large language model 中。该方法作为对齐连接器增强了 large language model 的长视频推理能力，并在 vlm 任务及视频理解基准上实现了精度与效率的最佳平衡。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">50. ClinDet-Bench: Beyond Abstention, Evaluating Judgment Determinability of LLMs in Clinical Decision-Making</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22771</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Yusuke Watanabe, Yohei Kobashi, Takeshi Kojima, Yusuke Iwasawa, Yasushi Okuno, Yutaka Matsuo<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22771v1">https://arxiv.org/abs/2602.22771v1</a><br/><b>Summary</b>: 针对临床决策中信息不完整导致**large language model**易出现误判或过度放弃的问题，本文提出了 ClinDet-Bench 基准，通过分解可判定与不可判定场景来评估模型识别判断确定性的能力。该研究揭示了现有基准的不足，并为医学等高风险领域中**large language model**的安全性提供了新的评估框架。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">51. AMA-Bench: Evaluating Long-Horizon Memory for Agentic Applications</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22769</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Yujie Zhao, Boqin Yuan, Junbo Huang, Haocheng Yuan, Zhongming Yu, Haozhou Xu, Lanxiang Hu, Abhilash Shankarampeta, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22769v1">https://arxiv.org/abs/2602.22769v1</a><br/><b>Summary</b>: 针对现有评估基准主要关注人机对话而忽视机器生成交互流的局限，本文提出 AMA-Bench 以评估大型语言模型在智能体应用中的长程记忆能力。通过引入包含因果图和工具增强检索的 AMA-Agent 架构，该方法有效解决了现有记忆系统缺乏因果性和客观信息的缺陷，实现了显著超越最强基线的性能表现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">52. Imagination Helps Visual Reasoning, But Not Yet in Latent Space</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22766</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: You Li, Chi Chen, Yanghao Li, Fanhu Zeng, Kaiyu Huang, Jinan Xu, Maosong Sun<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22766v1">https://arxiv.org/abs/2602.22766v1</a><br/><b>Summary</b>: 本文针对多模态大语言模型（Multimodal Large Language Model）中的潜在视觉推理机制，利用因果中介分析发现潜在 token（latent token）与输入及输出间存在显著的因果断连，从而挑战了该机制的必要性。为此，作者提出 CapImagine 方法，教导大型语言模型（Large Language Model）通过文本显式想象替代隐式推理，实验表明该方法在视觉语言模型（Vision Language Model, VLM）基准上显著优于依赖隐式潜在空间的复杂基线。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">53. Towards Better RL Training Data Utilization via Second-Order Rollout</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22765</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Zhe Yang, Yudong Wang, Rang Li, Zhifang Sui<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22765v1">https://arxiv.org/abs/2602.22765v1</a><br/><b>Summary</b>: 针对传统强化学习仅利用一阶采样优化大语言模型生成能力而忽略批判训练的不足，本文提出了一种基于二阶采样的统一训练框架。该方法通过为响应生成多个批判意见，实现生成与批判能力的联合训练，显著提升了训练数据的利用率。实验结果表明，该策略在相同数据下优于传统方法，并揭示了标签平衡及结果奖励噪声缓解的关键发现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">54. Distributed LLM Pretraining During Renewable Curtailment Windows: A Feasibility Study</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22760</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Philipp Wiesner, Soeren Becker, Brett Cornick, Dominik Scheinert, Alexander Acker, Odej Kao<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22760v1">https://arxiv.org/abs/2602.22760v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）训练的高能耗与可再生能源弃电浪费问题，本文提出了一种基于 Flower 联邦学习框架的分布式预训练方案，可在区域弃电窗口期间弹性切换本地与多站点同步。实验结果表明，该碳感知调度策略在保持训练质量的同时，将运营碳排放显著降低至单点基线的 5-12%。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">55. Towards Simulating Social Media Users with LLMs: Evaluating the Operational Validity of Conditioned Comment Prediction</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22752</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Nils Schwager, Simon Münker, Alistair Plum, Achim Rettinger<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22752v1">https://arxiv.org/abs/2602.22752v1</a><br/><b>Summary</b>: 该研究针对大语言模型（large language model）模拟社交媒体用户行为缺乏操作有效性的问题，提出了条件评论预测（CCP）任务框架以评估其能力。研究发现监督微调会导致形式与内容解耦，且模型能从行为历史中进行潜在推断，这挑战了现有提示范式并建议优先使用真实行为痕迹。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">56. SPATIALALIGN: Aligning Dynamic Spatial Relationships in Video Generation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22745</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Fengming Liu, Tat-Jen Cham, Chuanxia Zheng<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22745v1">https://arxiv.org/abs/2602.22745v1</a><br/><b>Summary</b>: 针对现有文生视频模型常忽略提示词中动态空间关系的问题，本文提出 SPATIALALIGN 自改进框架，利用零阶正则化直接偏好优化（DPO）微调模型以增强空间对齐能力。该方法设计了基于几何的 DSR-SCORE 指标，突破了以往依赖视觉语言模型（VLM）评估的局限，并通过专用数据集验证了其在多模态生成任务上的显著优势。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">57. Extending Czech Aspect-Based Sentiment Analysis with Opinion Terms: Dataset and LLM Benchmarks</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22730</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Jakub Šmíd, Pavel Přibáň, Pavel Král<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22730v1">https://arxiv.org/abs/2602.22730v1</a><br/><b>Summary</b>: 本文针对捷克语基于方面的情感分析任务，构建了包含意见术语标注的新数据集，并利用大型语言模型（LLM）评估了其在多语言设置下的性能。通过提出基于 LLM 的翻译与标签对齐方法，研究有效解决了跨语言挑战，确立了新基准并为低资源语言适配提供了可扩展方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">58. HulluEdit: Single-Pass Evidence-Consistent Subspace Editing for Mitigating Hallucinations in Large Vision-Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22727</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Yangguang Lin, Quan Fang, Yufei Li, Jiachen Sun, Junyu Gao, Jitao Sang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22727v1">https://arxiv.org/abs/2602.22727v1</a><br/><b>Summary</b>: 针对大视觉语言模型（Vision Language Model, LVLM）中的物体幻觉问题，HulluEdit 提出了一种基于正交子空间编辑的单遍干预框架，通过对模型潜在表示（latent token）分解来选择性抑制冲突先验而不影响视觉证据。实验表明，该多模态大语言模型（Multimodal Large Language Model）方法在显著降低幻觉的同时，保持了大语言模型（Large Language Model）的通用能力与推理效率，优于现有基线。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">59. AgentSentry: Mitigating Indirect Prompt Injection in LLM Agents via Temporal Causal Diagnostics and Context Purification</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22724</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Tian Zhang, Yiwei Xu, Juan Wang, Keyan Guo, Xiaoyang Xu, Bowen Xiao, Quanlong Guan, Jinlin Fan, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22724v1">https://arxiv.org/abs/2602.22724v1</a><br/><b>Summary</b>: 针对大语言模型（LLM）智能体在调用外部工具时易受间接提示注入（IPI）攻击的问题，AgentSentry 提出了一种基于时序因果诊断和上下文净化的推理时防御框架，首次将多轮 IPI 建模为时序因果接管。该方法通过受控反事实重执行定位攻击点并移除恶意偏差，实验表明其在消除攻击的同时保持了高任务效用，显著优于现有基线且未损害良性性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">60. Replacing Multi-Step Assembly of Data Preparation Pipelines with One-Step LLM Pipeline Generation for Table QA</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22721</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Fengyu Li, Junhao Zhu, Kaishi Song, Lu Chen, Zhongming Yao, Tianyi Li, Christian S. Jensen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22721v1">https://arxiv.org/abs/2602.22721v1</a><br/><b>Summary</b>: 针对基于大语言模型（Large Language Model）的表格问答任务中多步流水线组装导致的高延迟与高成本问题，本文提出 Operation-R1 框架，利用强化学习训练轻量级大语言模型以实现单步数据准备流水线生成。该方法通过自监督奖励与操作合并机制增强鲁棒性，实验表明其在显著提升准确率的同时，实现了表格压缩率降低 79% 及成本减少 2.2 倍的关键贡献。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">61. RLHFless: Serverless Computing for Efficient RLHF</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22718</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Rui Wei, Hanfei Yu, Shubham Jain, Yogarajan Sivakumar, Devesh Tiwari, Jian Li, Seung-Jong Park, Hao Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22718v1">https://arxiv.org/abs/2602.22718v1</a><br/><b>Summary</b>: 针对大型语言模型（Large Language Model）的强化学习人类反馈（RLHF）训练中，传统服务器架构因无法适应动态资源需求而导致效率低下的问题，本文提出了基于无服务器计算的 RLHFless 框架。该方法通过预计算共享前缀和成本感知的 Actor 扩展策略优化资源分配，实验显示其相比最先进基线实现了高达 1.35 倍的加速和 44.8% 的成本降低。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">62. SoPE: Spherical Coordinate-Based Positional Embedding for Enhancing Spatial Perception of 3D LVLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22716</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CV<br/><b>Authors</b>: Guanting Ye, Qiyan Zhao, Wenhao Yu, Liangyu Yuan, Mingkai Li, Xiaofeng Zhang, Jianmin Ji, Yanyong Zhang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22716v1">https://arxiv.org/abs/2602.22716v1</a><br/><b>Summary</b>: 针对现有基于大语言模型的 3D 多模态视觉语言模型（LVLM）中旋转位置编码（RoPE）无法保留三维空间结构及忽略角度依赖的问题，本文提出了基于球坐标的位置嵌入（SoPE）。该方法通过将点云潜在 token 映射至三维球坐标空间并结合多尺度频率混合策略，显著增强了模型的空间感知与几何表征能力，在多个 3D 场景基准及真实部署中验证了其有效性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">63. Enhancing Geometric Perception in VLMs via Translator-Guided Reinforcement Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22703</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Hao Yu, Shuning Jia, Guanghao Li, Wenhao Jiang, Chun Yuan<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22703v1">https://arxiv.org/abs/2602.22703v1</a><br/><b>Summary</b>: 针对视觉语言模型（Vision Language Model, VLM）在几何推理中感知能力受限的问题，本文提出 GeoPerceive 基准与 GeoDPO 框架，利用翻译器引导的强化学习增强多模态大语言模型的几何理解能力。实验证明，GeoDPO 通过提供细粒度奖励信号，在域内、域外及下游推理任务上均取得显著增益，大幅提升了 VLM 的几何感知表现并优于监督微调。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">64. IMMACULATE: A Practical LLM Auditing Framework via Verifiable Computation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22700</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Yanpei Guo, Wenjie Qu, Linyu Wu, Shengfang Zhai, Lionel Z. Wang, Ming Xu, Yue Liu, Binhang Yuan, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22700v1">https://arxiv.org/abs/2602.22700v1</a><br/><b>Summary</b>: 针对商业大型语言模型（LLM）作为黑盒服务时存在的信任风险，如模型替换和计费欺诈，本文提出了 IMMACULATE 实用审计框架。该方法基于可验证计算技术，通过抽样审计请求来检测经济动机偏差，无需依赖可信硬件或模型内部信息。实验表明，该框架能以低于 1% 的吞吐量开销可靠区分良性与恶意执行，为大型语言模型的安全审计提供了高效解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">65. Tokenization, Fusion and Decoupling: Bridging the Granularity Mismatch Between Large Language Models and Knowledge Graphs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22698</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Siyue Su, Jian Yang, Bo Li, Guanglin Niu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22698v1">https://arxiv.org/abs/2602.22698v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）在知识图谱补全任务中存在的粒度不匹配问题，本文提出 KGT 框架，利用专用实体令牌（latent token）构建统一特征表示并通过关系引导机制融合结构与文本信息。该方法通过解耦预测头实现语义与结构推理的独立处理，实验证明其在多个基准上优于现有最先进方法，有效解决了传统方法难以兼顾文本语义与图结构完整性的难题。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">66. Reinforcing Real-world Service Agents: Balancing Utility and Cost in Task-oriented Dialogue</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22697</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Ning Gao, Wei Zhang, Yuqin Dai, Ling Shi, Ziyin Wang, Yujie Wang, Wei He, Jinpeng Wang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22697v1">https://arxiv.org/abs/2602.22697v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）在任务导向对话中难以平衡共情沟通与预算决策的挑战，本文提出 InteractCS-RL 框架，将对话重构为多粒度强化学习过程。该方法通过构建用户中心交互环境并引入成本感知多轮策略优化（CMPO），利用混合优势估计策略有效探索了效用与成本的帕累托边界。实验表明，该模型在真实业务场景及工具交互基准测试中显著优于现有基线，有效提升了服务代理的实用性与鲁棒性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">67. No Caption, No Problem: Caption-Free Membership Inference via Model-Fitted Embeddings</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22689</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Joonsung Jeon, Woo Jae Kim, Suhyeon Ha, Sooel Son, Sung-Eui Yoon<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22689v1">https://arxiv.org/abs/2602.22689v1</a><br/><b>Summary</b>: 针对现有基于视觉语言模型（VLM）或多模态大语言模型的成员推断攻击依赖真实标题的局限，本文提出 MoFit 框架，利用模型拟合嵌入在潜在空间构建合成条件以替代文本描述。该方法避免了依赖大型语言模型生成的 Caption，通过优化图像扰动增强成员样本区分度。实验表明，MoFit 在无标题场景下显著优于 VLM 基线，性能接近依赖真实标题的方法。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">68. SUPERGLASSES: Benchmarking Vision Language Models as Intelligent Agents for AI Smart Glasses</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22683</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CV<br/><b>Authors</b>: Zhuohang Jiang, Xu Yuan, Haohao Qu, Shanru Lin, Kanglong Liu, Wenqi Fan, Qing Li<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22683v1">https://arxiv.org/abs/2602.22683v1</a><br/><b>Summary</b>: 现有 Vision Language Model (VLM) 在智能眼镜场景中常因缺乏真实数据及前置物体识别能力而表现受限。为此，本文构建了基于真实采集数据的 SUPERGLASSES 基准测试，并提出了 SUPERLENS 多模态大语言模型代理。该代理通过集成自动物体检测与检索增强生成技术，实现了超越 GPT-4o 的顶尖性能，填补了特定任务解决方案的空白。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">69. Accelerating LLM Pre-Training through Flat-Direction Dynamics Enhancement</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22681</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Shuchen Zhu, Rizhen Hu, Mingze Wang, Mou Sun, Xue Wang, Kun Yuan, Zaiwen Wen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22681v1">https://arxiv.org/abs/2602.22681v1</a><br/><b>Summary</b>: 针对**大语言模型**预训练面临的高昂计算成本及优化景观各向异性难题，本文提出了基于黎曼常微分方程框架的 LITE 加速策略。该方法通过在平坦方向上应用更大的 Hessian 阻尼系数和学习率，增强了训练动力学并优化了更新路径。实验证明，LITE 能显著加速多种架构下的**大语言模型**预训练，为高效优化提供了理论支持。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">70. Toward Personalized LLM-Powered Agents: Foundations, Evaluation, and Future Directions</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22680</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Yue Xu, Qian Chen, Zizhan Ma, Dongrui Liu, Wenxuan Wang, Xiting Wang, Li Xiong, Wenjie Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22680v1">https://arxiv.org/abs/2602.22680v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）驱动的智能体在长程交互中需适应个体用户的挑战，本文通过综述构建了涵盖画像建模、记忆、规划及行动执行的结构化框架。该研究进一步分析了用户信号的传播机制与评估基准，为未来开发可扩展、自适应的个性化智能体系统提供了明确的路线图。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">71. Compress the Easy, Explore the Hard: Difficulty-Aware Entropy Regularization for Efficient LLM Reasoning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22642</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Qin-Wen Luo, Sheng Ren, Xiang Chen, Rui Liu, Jun Fang, Naiqiang Tan, Sheng-Jun Huang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22642v1">https://arxiv.org/abs/2602.22642v1</a><br/><b>Summary</b>: 针对现有大语言模型推理压缩方法易引发熵坍塌从而损害复杂问题求解能力的问题，本文提出了 CEEH 难度感知强化学习框架。该方法通过动态评估实例难度，对简单问题实施激进压缩，同时对困难问题保留搜索空间以平衡推理效率与准确性。实验表明，该策略在显著缩短响应长度的同时保持了与基线模型相当的准确率，有效提升了推理效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">72. MobilityBench: A Benchmark for Evaluating Route-Planning Agents in Real-World Mobility Scenarios</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22638</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Zhiheng Song, Jingshuai Zhang, Chuan Qin, Chao Wang, Chao Chen, Longfei Xu, Kaikui Liu, Xiangxiang Chu, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22638v1">https://arxiv.org/abs/2602.22638v1</a><br/><b>Summary</b>: 针对基于 large language model 的路线规划代理在真实世界场景中因服务非确定性而难以系统评估的问题，本研究提出了 MobilityBench 基准，利用匿名真实数据与确定性 API 回放沙箱实现了可复现的端到端评测。该基准设计了包含结果有效性、指令理解及工具使用在内的多维度评估协议，对多个代理在不同出行场景下的行为与性能进行了深入分析。实验结果表明，当前模型在基础任务上表现尚可，但在偏好约束的路径规划方面仍存在显著不足，揭示了个性化移动应用的改进空间。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">73. Instruction-based Image Editing with Planning, Reasoning, and Generation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22624</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CV<br/><b>Authors</b>: Liya Ji, Chenyang Qi, Qifeng Chen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22624v1">https://arxiv.org/abs/2602.22624v1</a><br/><b>Summary</b>: 针对指令图像编辑中场景理解与生成能力割裂的挑战，本文提出一种融合规划、推理和生成的多模态大语言模型框架。该方法利用大语言模型进行思维链规划，并通过视觉语言模型（VLM / Multimodal Large Language Model）精准推理编辑区域，最终结合扩散模型实现高质量图像编辑。实验证明，该方案有效弥合了理解与生成的鸿沟，在复杂真实图像上展现出卓越的编辑性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">74. Semantic Tube Prediction: Beating LLM Data Efficiency with JEPA</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22617</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Hai Huang, Yann LeCun, Randall Balestriero<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22617v1">https://arxiv.org/abs/2602.22617v1</a><br/><b>Summary</b>: 针对大语言模型（Large Language Model）受限于数据效率缩放定律的问题，本文引入测地线假设并提出语义管预测（STP）任务。该方法作为一种 JEPA 风格的正则化器，将隐藏状态轨迹约束在流形的管状邻域内，从而提升信噪比并保留多样性。实验显示，该策略使大语言模型仅需 16 倍更少的训练数据即可匹配基线精度，直接违反了 Chinchilla 风格的缩放定律。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">75. Transformers converge to invariant algorithmic cores</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22600</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Joshua S. Schiffman<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22600v1">https://arxiv.org/abs/2602.22600v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）内部机制难以解析的问题，该研究提出提取“算法核心”作为任务性能的必要且充分子空间。研究发现独立训练的 Transformer 虽权重配置不同，但收敛于相同的低维不变结构，揭示了跨训练运行和规模的共享计算本质。这一结果建议机械可解释性应聚焦于这些不变的计算核心，而非特定的实现细节。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">76. pQuant: Towards Effective Low-Bit Language Models via Decoupled Linear Quantization-Aware Training</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22592</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Wenzheng Zhang, Bingzheng Liu, Yang Hu, Xiaoying Bai, Wentao Zhang, Bin Cui<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22592v1">https://arxiv.org/abs/2602.22592v1</a><br/><b>Summary</b>: 针对极低比特大语言模型（LLM）量化中参数敏感度同质化导致精度受限的问题，本文提出 pQuant 方法，通过将线性层解耦为高效 1 比特分支与高精度敏感参数分支来优化模型表达力。该方法利用特征缩放引导参数分配并扩展为稀疏专家结构，在极低比特设置下实现了最先进的性能表现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">77. Search-P1: Path-Centric Reward Shaping for Stable and Efficient Agentic RAG Training</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22576</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Tianle Xia, Ming Xu, Lingxiang Hu, Yiding Sun, Wenwei Li, Linfang Shang, Liqun Liu, Peng Shu, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22576v1">https://arxiv.org/abs/2602.22576v1</a><br/><b>Summary</b>: 针对传统检索增强生成在处理复杂多步推理时的不足及现有强化训练方法奖励稀疏的问题，本文提出 Search-P1 框架以优化**大语言模型**的代理式 RAG 训练。该方法通过路径中心奖励塑造和双轨路径评分机制，有效提取失败样本的学习信号，并在多个问答基准上实现了平均 7.7 点的准确率显著提升。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">78. Addressing Climate Action Misperceptions with Generative AI</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22564</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Miriam Remshard, Yara Kyrychenko, Sander van der Linden, Matthew H. Goldberg, Anthony Leiserowitz, Elena Savoia, Jon Roozenbeek<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22564v1">https://arxiv.org/abs/2602.22564v1</a><br/><b>Summary</b>: 针对气候关注者对减排行动存在误解的问题，本研究招募参与者比较了个性化气候大语言模型与网络搜索及其他干预措施的效果。结果显示，只有配备气候知识并提供个性化反馈的大语言模型显著提升了参与者对行动影响的理解及采纳高影响力行为的意愿。该研究强调了大语言模型在提供可操作指导以推动亲气候行为改变方面的关键潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">79. CourtGuard: A Model-Agnostic Framework for Zero-Shot Policy Adaptation in LLM Safety</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22557</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.LG<br/><b>Authors</b>: Umid Suleymanov, Rufiz Bayramov, Suad Gafarli, Seljan Musayeva, Taghi Mammadov, Aynur Akhundlu, Murat Kantarcioglu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22557v1">https://arxiv.org/abs/2602.22557v1</a><br/><b>Summary</b>: 针对大语言模型安全机制中静态分类器适应性差的问题，CourtGuard 提出了一种基于检索增强多智能体辩论的模型无关框架，通过外部政策文档驱动对抗性辩论实现零样本策略适配。该方法无需微调即可在多个安全基准上超越专用基线，并成功泛化至域外任务及支持自动化数据策展与审计。这一研究证明了将安全逻辑与模型权重解耦能为人工智能治理提供灵活、可解释且高效的解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">80. Multilingual Safety Alignment Via Sparse Weight Editing</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22554</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Jiaming Liang, Zhaoxin Wang, Handing Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22554v1">https://arxiv.org/abs/2602.22554v1</a><br/><b>Summary</b>: 针对大语言模型在低资源语言中存在安全漏洞且现有微调方法成本高昂的问题，本文提出了一种基于稀疏权重编辑的训练无关对齐框架。该方法利用安全神经元的稀疏性，将跨语言对齐转化为约束线性变换并推导闭式解，从而将有害表示映射至安全子空间。实验结果显示，该方案在无需训练的情况下显著降低了低资源语言的攻击成功率，同时有效保留了模型的通用推理能力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">81. Requesting Expert Reasoning: Augmenting LLM Agents with Learned Collaborative Intervention</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22546</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Zhiming Wang, Jinwei He, Feng Lu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22546v1">https://arxiv.org/abs/2602.22546v1</a><br/><b>Summary</b>: 针对大型语言模型（Large Language Model）智能体在专业领域因缺乏长尾知识而失效的问题，本文提出 AHCE 框架，通过人类反馈模块学习将专家作为交互式推理工具进行按需协同干预。实验证明，该方法在 Minecraft 任务中将正常与高难度场景的成功率分别提升 32% 和近 70%，展示了通过主动请求专家推理增强智能体能力的有效性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">82. Ruyi2 Technical Report</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22543</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI, cs.CL<br/><b>Authors</b>: Huan Song, Shuyu Tian, Junyi Hao, Minxiu Xu, Hongjun An, Yiliang Song, Jiawei Shao, Xuelong Li<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22543v1">https://arxiv.org/abs/2602.22543v1</a><br/><b>Summary</b>: 针对**大型语言模型**（LLM）部署成本高及延迟大的问题，Ruyi2 提出基于 Megatron-LM 的“家族模型”策略，解决了现有自适应方法在分布式训练中的优化复杂性难题。该方法通过 3D 并行训练实现高效变量深度计算，在获得 2-3 倍加速的同时确立了“一次训练，多端部署”的新范式。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">83. Agentic AI for Intent-driven Optimization in Cell-free O-RAN</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22539</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.AI<br/><b>Authors</b>: Mohammad Hossein Shokouhi, Vincent W. S. Wong<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22539v1">https://arxiv.org/abs/2602.22539v1</a><br/><b>Summary</b>: 针对开放无线接入网中复杂意图协同优化的缺失，本文提出了一种基于大语言模型（large language model）的智能体框架，通过参数高效微调实现多智能体协作以完成意图翻译与资源调度。该方法在节能模式下减少了 41.93% 的活跃单元，并相比独立部署方案降低了 92% 的内存占用。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">84. Cognitive Models and AI Algorithms Provide Templates for Designing Language Agents</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22523</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Ryan Liu, Dilip Arumugam, Cedegao E. Zhang, Sean Escola, Xaq Pitkow, Thomas L. Griffiths<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22523v1">https://arxiv.org/abs/2602.22523v1</a><br/><b>Summary</b>: 针对单一**大语言模型**难以独立解决复杂任务且多模型协作模式尚不明确的问题，本文主张从认知模型和 AI 算法中寻找模块化语言智能体的设计蓝图。作者形式化了智能体模板以规范各**大语言模型**的角色分工与功能组合，并通过调研现有研究揭示了其背后的认知科学原理。该工作强调受认知科学启发的智能体模板是构建高效、可解释语言智能体的有力工具。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">85. Reinforcement-aware Knowledge Distillation for LLM Reasoning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22495</code> | <b>Published</b>: 2026-02-26<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Zhaoyang Zhang, Shuli Jiang, Yantao Shen, Yuting Zhang, Dhananjay Ram, Shuo Yang, Zhuowen Tu, Wei Xia, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22495v1">https://arxiv.org/abs/2602.22495v1</a><br/><b>Summary</b>: 针对强化学习后训练大语言模型推理成本高，且现有知识蒸馏方法在结合强化学习时存在分布不匹配与目标干扰的问题，本文提出 RL 感知蒸馏（RLAD）。该方法核心采用信任区域比率蒸馏（TRRD），利用类 PPO 的似然比目标替代传统 KL 正则化，在确保学生轨迹优势感知的同时自然平衡探索与模仿。实验表明，RLAD 在多种逻辑与数学基准测试中均优于离线蒸馏及标准 GRPO 等基线方法。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">86. Large Language Models are Algorithmically Blind</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21947</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Sohan Venkatesh, Ashish Mahendran Kurapath, Tejas Melkote<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21947v2">https://arxiv.org/abs/2602.21947v2</a><br/><b>Summary</b>: 尽管大型语言模型（large language model）展现了广泛的知识广度，但其对计算过程的推理能力仍存在严重不足，即所谓的“算法盲视”。本研究利用因果发现作为测试基准，通过对比大规模算法执行的地面真值，发现模型预测范围远超真实置信区间且多数表现不如随机猜测。这一发现揭示了模型依赖记忆而非原则性推理，指出了声明性知识与校准后的程序化预测之间的根本差距。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">87. SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21818</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Guibin Chen, Dixuan Lin, Jiangping Yang, Youqiang Zhang, Zhengcong Fei, Debang Li, Sheng Chen, Chaofeng Ao, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21818v2">https://arxiv.org/abs/2602.21818v2</a><br/><b>Summary</b>: SkyReels V4 针对视频音频联合生成及编辑的统一化挑战，提出了一种集成多模态大语言模型（MMLM）的双流多模态扩散 Transformer 架构，利用其强大的指令遵循能力处理复杂多模态输入。该模型作为首个支持电影级分辨率的高效视频基础模型，成功将多模态大语言模型的能力拓展至长时长视频的联合生成与统一编辑任务中，显著提升了多模态生成的质量与效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">88. Enhancing Multi-Modal LLMs Reasoning via Difficulty-Aware Group Normalization</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21743</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Jinghan Li, Junfeng Fang, Jinda Lu, Yuan Wang, Xiaoyan Guo, Tianyu Zhang, Xiang Wang, Xiangnan He<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21743v2">https://arxiv.org/abs/2602.21743v2</a><br/><b>Summary</b>: 针对多模态大语言模型在强化学习训练中因极端样本导致标准化不稳定的问题，本文提出了难度感知组归一化方法（Durian）。该方法通过量化视觉复杂度与推理不确定性对样本进行难度分组并共享标准差，有效消除了异常值干扰。实验结果表明，该方法显著提升了视觉语言模型及大语言模型的推理稳定性，在多个多模态基准测试中取得了优异的性能增益。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">89. Muon+: Towards Better Muon via One Additional Normalization Step</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21545</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Ruijie Zhang, Yequan Zhao, Ziyue Liu, Zhengyang Wang, Zheng Zhang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21545v2">https://arxiv.org/abs/2602.21545v2</a><br/><b>Summary</b>: 针对大型语言模型（large language model）预训练中优化器性能受限的问题，本文提出了引入额外归一化步骤的 Muon+ 方法。该方法通过改进梯度正交化流程，在广泛模型规模下显著降低了训练和验证困惑度。实验结果表明，Muon+ 在计算最优训练 regime 下能为大型语言模型提供一致且有效的性能提升。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">90. Importance of Prompt Optimisation for Error Detection in Medical Notes Using Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22483</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Craig Myles, Patrick Schrempf, David Harris-Birtill<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22483v1">https://arxiv.org/abs/2602.22483v1</a><br/><b>Summary</b>: 针对医疗文本错误可能引发治疗风险的问题，本文研究了自动提示优化在大型语言模型（large language model）错误检测中的重要性。通过引入遗传帕累托（GEPA）算法，该方法显著提升了 GPT-5 和 Qwen3-32B 的准确率，在 MEDEC 基准上达到最先进水平并接近医生表现。该研究证实了提示优化对于增强医疗文本分析性能的关键贡献。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">91. Mind the Gap in Cultural Alignment: Task-Aware Culture Management for Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22475</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Binchi Zhang, Xujiang Zhao, Jundong Li, Haifeng Chen, Zhengzhang Chen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22475v1">https://arxiv.org/abs/2602.22475v1</a><br/><b>Summary</b>: 针对现有文化对齐方法在大型语言模型应用中存在的跨文化干扰及任务目标不匹配问题，本文提出了 CultureManager 任务感知文化管理管道。该方法通过合成任务导向的文化数据并利用文化路由器管理多文化适配器，有效解决了不同文化规范间的冲突。实验证明，任务适配与模块化策略对于实现大型语言模型的有效文化对齐至关重要。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">92. When to Act, Ask, or Learn: Uncertainty-Aware Policy Steering</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22474</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Jessie Yuan, Yilin Wu, Andrea Bajcsy<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22474v1">https://arxiv.org/abs/2602.22474v1</a><br/><b>Summary</b>: 针对视觉语言模型（VLM）在多模态大语言模型应用中因校准不足导致机器人策略调整失效的问题，本文提出不确定性感知策略调整（UPS）框架。该方法利用共形预测校准 VLM 与预训练策略，根据语义任务不确定性和动作可行性动态选择执行、询问或干预策略。实验表明，UPS 能有效区分不同场景并最小化昂贵的人工干预，实现了基于少量反馈的持续学习与部署适应。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">93. Beyond Dominant Patches: Spatial Credit Redistribution For Grounded Vision-Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22469</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Niamul Hassan Samin, Md Arifur Rahman, Abdullah Ibne Hanif, Juena Ahmed Noshin, Md Ashikur Rahman<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22469v1">https://arxiv.org/abs/2602.22469v1</a><br/><b>Summary</b>: 针对视觉语言模型（Vision-Language Model, VLM）因空间信用崩溃导致的幻觉问题，本文提出了一种无需训练的空间信用重分配（SCR）方法，通过重新分配潜在令牌（latent token）的隐藏状态激活来纠正注意力偏差。该方法在多模态大语言模型中显著降低了幻觉率，证实了其对底层大型语言模型推理的有效改善，且推理开销远低于现有干预技术。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">94. MammoWise: Multi-Model Local RAG Pipeline for Mammography Report Generation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22462</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Raiyan Jahangir, Nafiz Imtiaz Khan, Amritanand Sudheerkumar, Vladimir Filkov<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22462v1">https://arxiv.org/abs/2602.22462v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（Vision Language Model）依赖云端系统导致隐私与适应性受限的问题，MammoWise 提出了一种基于开源大语言模型（Large Language Model）和本地部署的多模态大语言模型（Multimodal Large Language Model）管道，利用 VLM 结合检索增强生成（RAG）与参数高效微调实现乳腺 X 光报告生成。实验证明，该框架在保持报告质量的同时显著提升了分类准确性，为医疗影像分析提供了可复现且可扩展的本地化解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">95. Exploring Multimodal LMMs for Online Episodic Memory Question Answering on the Edge</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22455</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Giuseppe Lando, Rosario Forte, Antonino Furnari<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22455v1">https://arxiv.org/abs/2602.22455v1</a><br/><b>Summary</b>: 针对可穿戴设备云端部署引发的隐私与延迟挑战，本研究探索了利用多模态大语言模型（MLLM）在边缘端实现实时情景记忆问答的可行性。该方法设计了双异步线程架构，利用视觉语言模型（VLM）将视频流转化为轻量级文本记忆，并依托大型语言模型（LLM）完成推理。实验表明，该边缘方案在消费级 GPU 上达到了接近云端的准确率与低首字延迟，验证了多模态大语言模型在隐私保护场景下的应用潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">96. SimpleOCR: Rendering Visualized Questions to Teach MLLMs to Read</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22426</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV, cs.LG<br/><b>Authors</b>: Yibo Peng, Peng Xia, Ding Zhong, Kaide Zeng, Siwei Han, Yiyang Zhou, Jiaqi Liu, Ruiyi Zhang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22426v1">https://arxiv.org/abs/2602.22426v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM）存在的“模态惰性”问题，即模型可能依赖文本提示而非真正读取图像中的文字，本文提出了 SimpleOCR 训练策略。该方法通过渲染可视化问题（VQ）强制 Vision Language Model (VLM) 激活视觉文本提取路径，有效消除了对大型语言模型（LLM）参数捷径的依赖，并在无需架构修改的情况下实现了极高的数据效率和性能提升。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">97. Causality $\neq$ Invariance: Function and Concept Vectors in LLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22424</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Gustaw Opiełka, Hannes Rosenbusch, Claire E. Stevenson<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22424v1">https://arxiv.org/abs/2602.22424v1</a><br/><b>Summary</b>: 本文探究**大语言模型**中的概念表示是否具有跨输入格式的不变性。研究通过表征相似性分析识别出比功能向量更具稳定性的概念向量，并对比了两者的特性。结果表明概念向量作为更鲁棒的**潜在**表示在跨语言和题型下展现出更好的泛化能力，揭示了因果性不等于不变性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">98. Scaling In, Not Up? Testing Thick Citation Context Analysis with GPT-5 and Fragile Prompts</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22359</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Arno Simons<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22359v1">https://arxiv.org/abs/2602.22359v1</a><br/><b>Summary</b>: 本研究探讨了大型语言模型（large language model）能否通过深度文本解读而非扩展标签来支持引文语境分析，并采用 GPT-5 的两阶段管道结合提示敏感性设计进行验证。实验发现提示框架会系统性地重塑模型的注意力与词汇分布，揭示了将此类模型作为可审查协同分析工具的机遇与风险。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">99. Decoder-based Sense Knowledge Distillation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22351</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Qitong Wang, Mohammed J. Zaki, Georgios Kollias, Vasileios Kalantzis<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22351v1">https://arxiv.org/abs/2602.22351v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）常忽视结构化词汇知识的挑战，本文提出了基于解码器的感知知识蒸馏（DSKD）框架，旨在将词典资源融入训练而不增加推理开销。实验表明，DSKD 显著提升了解码器在知识蒸馏任务中的性能，使生成式模型能够高效地继承结构化语义。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">100. Structure and Redundancy in Large Language Models: A Spectral Study via Random Matrix Theory</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22345</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Davide Ettori<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22345v1">https://arxiv.org/abs/2602.22345v1</a><br/><b>Summary</b>: 针对大语言模型 (LLM) 与视觉语言模型 (VLM) 在扩展中面临的可靠性与效率挑战，本研究基于随机矩阵理论分析隐藏激活的谱统计特性。提出的 EigenTrack 方法通过建模潜在 token 的谱演化，实现了多模态大语言模型中幻觉的实时检测；而 RMT-KD 则利用谱信息指导知识蒸馏，显著提升了模型的压缩率与能效。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">101. Decoding the Hook: A Multimodal LLM Framework for Analyzing the Hooking Period of Video Ads</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22299</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Kunpeng Zhang, Poppy Zhang, Shawndra Hill, Amel Awadelkarim<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22299v1">https://arxiv.org/abs/2602.22299v1</a><br/><b>Summary</b>: 针对视频广告“钩子期”因多模态信息交互复杂而难以评估的问题，本研究提出了一种基于多模态大语言模型（multimodal large language model）的分析框架。该方法利用大型语言模型结合帧采样策略提取关键视听特征，并通过主题建模生成高抽象度的广告影响分析。实证结果证实了该框架在预测广告转化指标方面的有效性，为视频广告优化提供了可扩展的视觉语言模型（VLM）应用方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">102. UpSkill: Mutual Information Skill Learning for Structured Response Diversity in LLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22296</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Devan Shah, Owen Yang, Daniel Yang, Chongyi Zheng, Benjamin Eysenbach<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22296v1">https://arxiv.org/abs/2602.22296v1</a><br/><b>Summary</b>: 针对标准强化学习方法在优化大语言模型（LLM）单次准确率时易抑制响应多样性的问题，本文提出 UpSkill 方法，通过将互信息技能学习（MISL）适配于大语言模型并在组相对策略优化（GRPO）中引入 token 级互信息奖励来优化 pass@k 正确性。实验表明，UpSkill 在不降低 pass@1 的情况下，使强基座模型的 pass@k 平均提升约 3%，证实了互信息目标对性能改进的关键作用。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">103. Manifold of Failure: Behavioral Attraction Basins in Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22291</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Sarthak Munshi, Manish Bhatt, Vineeth Sai Narajala, Idan Habler, AmmarnAl-Kahfah, Ken Huang, Blake Gatto<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22291v1">https://arxiv.org/abs/2602.22291v1</a><br/><b>Summary</b>: 针对现有 AI 安全研究忽视不安全区域表征的问题，本文提出利用 MAP-Elites 算法将漏洞搜索重构为质量多样性问题，从而系统映射大型语言模型的失败流形与行为吸引域。该方法通过“对齐偏差”指标揭示了模型间显著的脆弱性拓扑差异，并生成了比传统攻击方法更具解释性的全局安全景观图。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">104. OmniZip: Learning a Unified and Lightweight Lossless Compressor for Multi-Modal Data</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22286</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yan Zhao, Zhengxue Cheng, Junxuan Zhang, Dajiang Zhou, Qunshan Gu, Qi Wang, Li Song<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22286v1">https://arxiv.org/abs/2602.22286v1</a><br/><b>Summary</b>: 针对现有单模态压缩器冗余以及视觉语言模型（VLM）和多模态大语言模型（multimodal large language model）过于复杂的问题，本文提出了 OmniZip。该方法基于轻量级骨干网络，利用模态统一的分词器将数据编码为潜在令牌（latent token），在多种模态上显著优于 gzip 等基准，同时支持资源受限的边缘设备进行近实时推理。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">105. BrepCoder: A Unified Multimodal Large Language Model for Multi-task B-rep Reasoning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22284</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Mingi Kim, Yongjun Kim, Jungwoo Kang, Hyungki Kim<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22284v1">https://arxiv.org/abs/2602.22284v1</a><br/><b>Summary</b>: 针对现有 CAD 方法依赖特定任务模型且忽视标准 B-rep 格式的局限，本文提出了 BrepCoder，这是一种利用大语言模型（Large Language Model）代码生成能力的统一多模态大语言模型（Multimodal Large Language Model）。该方法通过将 B-rep 序列转化为类 Python 代码并进行两阶段训练，实现了对逆向工程及下游任务的统一推理，展现了作为通用 CAD 智能体的卓越泛化潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">106. Integrating Machine Learning Ensembles and Large Language Models for Heart Disease Prediction Using Voting Fusion</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22280</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Md. Tahsin Amin, Tanim Ahmmod, Zannatul Ferdus, Talukder Naemul Hasan Naem, Ehsanul Ferdous, Arpita Bhattacharjee, Ishmam Ahmed Solaiman, Nahiyan Bin Noor<br/><b>Summary Source</b>: extractive+zh-llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22280v1">https://arxiv.org/abs/2602.22280v1</a><br/><b>Summary</b>: 标题：基于投票融合集成机器学习集成与大语言模型的心脏病预测 arXiv ID: 2602.22280 摘要：大语言模型（LLM）的兴起带来了新的零样本和少样本推理能力，尽管机器学习（ML）算法，尤其是随机森林、XGBoost、LightGBM 和 CatBoost 等集成方法，在建模复杂非线性患者数据方面表现出色，且通常能击败...</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">107. RETLLM: Training and Data-Free MLLMs for Multimodal Information Retrieval</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22278</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Dawei Su, Dongsheng Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22278v1">https://arxiv.org/abs/2602.22278v1</a><br/><b>Summary</b>: 针对现有基于多模态大语言模型（MLLM）的检索方法依赖训练且存在预训练不一致的问题，本文提出无需训练的RetLLM框架。该方法利用大语言模型（LLM）结合粗精两级流程与视觉增强模块直接预测检索分数，实验证明其在无训练场景下优于微调模型，展现了视觉语言模型强大的内在检索能力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">108. Sustainable LLM Inference using Context-Aware Model Switching</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22261</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yuvarani, Akashdeep Singh, Zahra Fathanah, Salsabila Harlen, Syeikha Syafura Al-Zahra binti Zahari, Hema Subramaniam<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22261v1">https://arxiv.org/abs/2602.22261v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）推理中因统一策略导致的高能耗问题，本文提出了一种融合缓存、规则评分及机器学习分类的上下文感知模型切换系统。实验结果表明，该方法通过动态选择适配任务复杂度的模型，在保持输出质量的同时实现了高达 67.5% 的能耗降低及显著的响应时间优化。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">109. Recovered in Translation: Efficient Pipeline for Automated Translation of Benchmarks and Datasets</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22207</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Hanna Yukhymenko, Anton Alexandrov, Martin Vechev<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22207v1">https://arxiv.org/abs/2602.22207v1</a><br/><b>Summary</b>: 针对现有翻译质量不一致严重影响多语言**大语言模型**评估可靠性的问题，本文提出了一种结合通用自改进与 T-RANK 方法的自动化框架。该方法通过扩展测试时计算策略，在保留任务结构与语言细微差别的同时实现了高质量数据集本地化，并发布了更准确的评估基准以促进多语言 AI 发展。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">110. Dynamic Personality Adaptation in Large Language Models via State Machines</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22157</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.LG<br/><b>Authors</b>: Leon Pielage, Ole Hätscher, Mitja Back, Bernhard Marschall, Benjamin Risse<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22157v1">https://arxiv.org/abs/2602.22157v1</a><br/><b>Summary</b>: 针对大语言模型（Large Language Model）难以在对话中动态调整性格表达的局限，本文提出了一种基于状态机的动态人格模拟框架，利用潜在人格状态作为动态变量来系统性地重配置系统提示。该方法通过模块化评分管道实现与特定模型无关的灵活适配，并在医学教育场景中验证了其有效影响用户行为的能力，为人机交互提供了可行的解决方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">111. Provable Last-Iterate Convergence for Multi-Objective Safe LLM Alignment via Optimistic Primal-Dual</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22146</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yining Li, Peizhong Ju, Ness Shroff<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22146v1">https://arxiv.org/abs/2602.22146v1</a><br/><b>Summary</b>: 针对大语言模型（Large Language Model）在安全对齐任务中标准对偶方法易出现最后一轮迭代不稳定的问题，本文提出了一种引入预测更新的乐观对偶（OPD）算法框架，并通过统一现有对齐方法稳定了鞍点动力学。该研究建立了严格的最后一轮迭代收敛性保证，填补了约束强化理论与实际 RLHF 实践之间的关键理论差距。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">112. When AI Writes, Whose Voice Remains? Quantifying Cultural Marker Erasure Across World English Varieties in Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22145</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Satyam Kumar Navneet, Joydeep Chandra, Yong Zhang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22145v1">https://arxiv.org/abs/2602.22145v1</a><br/><b>Summary</b>: 该研究揭示了**大语言模型**在文本处理中存在“文化幽灵化”现象，即系统性地抹除非母语英语变体的独特语言标记。研究者通过引入身份擦除率和语义保留分数等新指标，量化了模型在维持高语义相似性的同时丢失文化特征的矛盾。实验表明，使用显式的文化保护提示策略可在不牺牲语义质量的前提下，显著降低此类文化标记的擦除率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">113. NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22144</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.CV<br/><b>Authors</b>: Lingfeng Ren, Weihao Yu, Runpeng Yu, Xinchao Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22144v1">https://arxiv.org/abs/2602.22144v1</a><br/><b>Summary</b>: 针对多模态大语言模型（Multimodal Large Language Model）中普遍存在的物体幻觉问题，本研究分析发现幻觉主要源于大型语言模型（Large Language Model）解码器的强先验。为此，作者提出了无需训练的 NoLan 框架，通过动态抑制语言先验来优化视觉语言模型（Vision Language Model）的输出分布，从而显著降低各类 VLM 上的幻觉并提升生成准确性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">114. WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22142</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Yulin Zhang, Cheng Shi, Sibei Yang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22142v1">https://arxiv.org/abs/2602.22142v1</a><br/><b>Summary</b>: 针对现有 multimodal large language model 在流式视频处理中因时序无关性导致的理解偏差，WeaveTime 提出了一种无需架构修改的高效框架。该方法通过轻量级时序重建目标增强 vision language model 的时序感知表示，并利用动态焦点缓存机制优化 large language model 对历史与当前信息的关注。实验证明，该方案显著提升了 VLM 在严格因果约束下的流式推理准确率与效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">115. Brain3D: Brain Report Automation via Inflated Vision Transformers in 3D</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22098</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Mariano Barone, Francesco Di Serio, Giuseppe Riccio, Antonio Romano, Marco Postiglione, Antonino Ferraro, Vincenzo Moscato<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22098v1">https://arxiv.org/abs/2602.22098v1</a><br/><b>Summary</b>: 针对现有医学视觉语言模型（VLM）依赖 2D 切片导致脑 MRI 空间上下文碎片化的问题，本文提出 Brain3D，一种通过将 2D 编码器膨胀为原生 3D 架构并与因果大语言模型（LLM）分阶段对齐的框架。作为专为神经放射学定制的多模态大语言模型，Brain3D 在 BraTS 数据集上取得了 0.951 的临床病理 F1 分数，显著优于传统 2D 基线且保持高特异性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">116. Confidence-Driven Multi-Scale Model Selection for Cost-Efficient Inference</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22090</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Bo-Wei Chen, Chung-Chi Chen, An-Zi Yen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22090v1">https://arxiv.org/abs/2602.22090v1</a><br/><b>Summary</b>: 针对大型语言模型（large language model）推理中性能与计算成本难以平衡的问题，本文提出了一种基于置信度的多尺度模型选择策略，通过动态评估任务难度将简单样本路由至小模型、复杂样本交由大模型处理。实验显示，该方案在保持与大模型相当准确率的同时，显著降低了 20% 至 40% 的计算成本及 API 令牌消耗，为资源受限场景下的高效部署提供了有效途径。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">117. Understanding Artificial Theory of Mind: Perturbed Tasks and Reasoning in Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22072</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Christian Nickel, Laura Schrewe, Florian Mai, Lucie Flek<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22072v1">https://arxiv.org/abs/2602.22072v1</a><br/><b>Summary</b>: 本研究针对**大语言模型**（LLM）的理论思维（ToM）能力进行探究，通过构建含扰动任务的标注数据集并结合思维链（CoT）提示来评估其鲁棒性。结果显示任务扰动会导致 LLM 的 ToM 能力急剧下降，质疑了其具备真实 ToM 的观点，同时指出 CoT 提示虽整体有效但在特定场景下可能降低准确率，需选择性应用。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">118. RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22033</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Yanqiu Yu, Zhifan Jin, Sijia Chen, Tongfei Chu, En Yu, Liman Liu, Wenbing Tao<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22033v1">https://arxiv.org/abs/2602.22033v1</a><br/><b>Summary</b>: 针对指代多目标跟踪在低能见度条件下的局限，本文提出 RGB-热成像 RT-RMOT 任务并构建首个 RefRT 数据集，设计了基于多模态大语言模型（MLLM）的 RTrack 框架。该框架利用视觉语言模型特性并结合强化学习策略优化大型语言模型的推理，有效解决了训练不稳定性，显著提升了全天候目标感知的准确性与完整性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">119. RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.22013</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: I-Hsiang Chen, Yu-Wei Liu, Tse-Yu Wu, Yu-Chien Chiang, Jen-Chien Yang, Wei-Ting Chen<br/><b>Summary Source</b>: extractive+zh-llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.22013v1">https://arxiv.org/abs/2602.22013v1</a><br/><b>Summary</b>: 标题：RobustVisRAG：视觉退化下的因果感知视觉检索增强生成 arXiv ID: 2602.22013 摘要：基于视觉的检索增强生成（VisRAG）利用视觉语言模型（VLMs），基于多模态证据联合检索相关视觉文档并生成有据可依的答案。结合提出的非因果失真建模与因果语义对齐目标，该框架...</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">120. Enhancing LLM-Based Test Generation by Eliminating Covered Code</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21997</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: WeiZhe Xu, Mengyu Liu, Fanxin Kong<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21997v1">https://arxiv.org/abs/2602.21997v1</a><br/><b>Summary</b>: 针对现有基于大语言模型的方法在处理复杂代码时因上下文过长导致覆盖率不足的问题，本文提出了一种结合上下文检索与覆盖代码消除的迭代式单元测试生成方法。该方法通过反复生成测试并剔除已覆盖代码段来简化任务，有效缓解了长上下文带来的推理限制。实验表明，该方案在开源项目上显著优于现有最先进方法，实现了更高的代码覆盖率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">121. PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21992</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Zekai Lin, Xu Zheng<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21992v1">https://arxiv.org/abs/2602.21992v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（VLM）在全景图像 3D 空间推理中受几何失真限制的问题，本文构建了 PanoEnv 基准并提出了一种基于强化学习的后训练框架。该方法利用组相对策略优化（GRPO）配合两阶段课程学习，有效增强了多模态大语言模型对三维环境的感知与理解能力。实验结果显示，该 7B 模型在多项指标上超越更大规模模型，成功将 3D 空间智能注入到视觉 - 语言系统中。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">122. CxMP: A Linguistic Minimal-Pair Benchmark for Evaluating Constructional Understanding in Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21978</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Miyu Oba, Saku Sugawara<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21978v1">https://arxiv.org/abs/2602.21978v1</a><br/><b>Summary</b>: 针对现有基准忽视构式形式与意义配对理解的问题，本文提出了基于构式语法的 CxMP 基准，利用最小对比对设计评估大型语言模型（LLM）的构式理解能力。实验结果表明，尽管句法能力早期出现，但大型语言模型在整合形式与语义方面仍存在局限，CxMP 为研究构式理解与学习轨迹提供了新框架。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">123. Global-Local Dual Perception for MLLMs in High-Resolution Text-Rich Image Translation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21956</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Junxin Lu, Tengfei Song, Zhanglin Wu, Pengfei Li, Xiaowei Liang, Hui Yang, Kun Chen, Ning Xie, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21956v1">https://arxiv.org/abs/2602.21956v1</a><br/><b>Summary</b>: 针对现有**多模态大语言模型**（MLLM）在处理高分辨率文本丰富图像时因布局杂乱导致的文本遗漏和语义漂移问题，本文提出 GLoTran 框架，通过全局 - 局部双重视觉感知策略增强**视觉语言模型**对细粒度细节的捕捉能力。此外，研究构建了包含 510K 样本的 GLoD 数据集，实验表明该方法显著提升了**大语言模型**在复杂场景下的翻译完整性与准确性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">124. MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21952</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Lingjun Zhang, Yujian Yuan, Changjie Wu, Xinyuan Chang, Xin Cai, Shuang Zeng, Linzhe Shi, Sijin Wang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21952v1">https://arxiv.org/abs/2602.21952v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（VLM）中文本思维链导致语义与物理空间脱节的问题，本文提出 MindDriver 渐进式多模态推理框架。该方法通过反馈引导的数据标注与强化微调优化多模态大语言模型的推理对齐，使其能模拟人类渐进式思考进行自动驾驶规划，并在评估中展现出优越性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">125. RADAR: Reasoning as Discrimination with Aligned Representations for LLM-based Knowledge Graph Reasoning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21951</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Bo Xue, Yuan Jin, Luoyi Fu, Jiaxin Ding, Xinbing Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21951v1">https://arxiv.org/abs/2602.21951v1</a><br/><b>Summary</b>: 现有基于 large language model 的知识图谱推理方法因倾向于记忆表面共现而限制泛化能力。为此，本文提出 RADAR，将推理重构为判别式实体选择，利用强化学习在表示空间直接推断以避免生成幻觉。实验表明，该方法在多个基准上取得了显著性能提升，并大幅增加了中间表示的任务相关互信息，展现了更鲁棒的推理能力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">126. MEDSYN: Benchmarking Multi-EviDence SYNthesis in Complex Clinical Cases for Multimodal Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21950</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Boqi Chen, Xudong Liu, Jiachuan Peng, Marianne Frey-Marti, Bang Zheng, Kyle Lam, Lin Li, Jianing Qiu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21950v1">https://arxiv.org/abs/2602.21950v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM）在复杂临床场景中难以综合异构视觉证据的问题，本文提出 MEDSYN 基准，评估了 18 个模型在鉴别诊断与最终诊断间的性能差距并揭示其合成能力缺陷。研究引入“证据敏感性”指标量化跨模态利用缺口，并开源了包含多种视觉证据类型的复杂案例数据集，为提升医疗视觉语言模型（VLM）的诊断准确性提供了新工具。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">127. Small Wins Big: Comparing Large Language Models and Domain Fine-Tuned Models for Sarcasm Detection in Code-Mixed Hinglish Text</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21933</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Bitan Majumder, Anirban Sen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21933v1">https://arxiv.org/abs/2602.21933v1</a><br/><b>Summary</b>: 针对代码混合 Hinglish 文本中讽刺检测的难题，本研究对比了多种大语言模型与微调后的 DistilBERT 模型。实验表明，在低资源场景下，经过领域自适应微调的小规模模型以 84% 的准确率超越了通用大语言模型，证明了针对特定任务微调小模型优于直接使用大语言模型进行推理。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">128. How to Take a Memorable Picture? Empowering Users with Actionable Feedback</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21877</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Francesco Laiti, Davide Talon, Jacopo Staiano, Elisa Ricci<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21877v1">https://arxiv.org/abs/2602.21877v1</a><br/><b>Summary</b>: 针对图像可记忆性研究缺乏拍摄时实时指导的问题，本文提出基于**多模态大语言模型**（MLLM）的 MemCoach 框架，通过无训练师生引导策略调整**视觉语言模型**内部激活，生成优化照片的可操作自然语言建议。研究同时引入 MemBench 基准，证实了该方法能成功将图像可记忆性从被动预测转变为对人类创作者的有效行动指导。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">129. DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21864</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL, cs.CV<br/><b>Authors</b>: Yanbin Wei, Jiangyue Yan, Chun Kang, Yang Chen, Hua Liu, James Kwok, Yu Zhang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21864v1">https://arxiv.org/abs/2602.21864v1</a><br/><b>Summary</b>: 针对现有 Vision-Language Model (VLM) 因依赖固定图拓扑表示而导致结构化图问答效果不佳的问题，本文提出 DynamicGTR 框架，通过动态选择最优表示来增强 Multimodal Large Language Model 的零样本推理能力。该方法无需额外训练即可实现准确率与简洁性的灵活权衡，并在基于 Large Language Model 的图算法及真实场景中展现出显著的迁移性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">130. Personalized Graph-Empowered Large Language Model for Proactive Information Access</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21862</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Chia Cheng Chang, An-Zi Yen, Hen-Hsen Huang, Hsin-Hsi Chen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21862v1">https://arxiv.org/abs/2602.21862v1</a><br/><b>Summary</b>: 针对个人难以回忆生活细节且现有记忆系统面临数据稀缺与训练成本高的问题，本文提出一种融合**大语言模型**（large language model）与个性化知识图谱的主动信息访问框架。该方法通过优化决策过程增强访问需求检测，并支持灵活替换基座模型以适应不断增长的日志数据。实验结果表明，该框架能有效识别遗忘事件，显著提升了用户回顾过往经历的效率。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">131. FewMMBench: A Benchmark for Multimodal Few-Shot Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21854</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Mustafa Dogan, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21854v1">https://arxiv.org/abs/2602.21854v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM）少样本学习评估的挑战，本文提出 FewMMBench 基准，旨在评估视觉语言模型（VLM）结合大型语言模型（LLM）在上下文学习与思维链提示下的表现。实验表明，尽管指令微调模型在零样本设置中表现优异，但增加演示或推理链收益有限，FewMMBench 因此成为诊断多模态大语言模型少样本能力的严谨测试平台。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">132. DocDjinn: Controllable Synthetic Document Generation with VLMs and Handwriting Diffusion</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21824</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Marcel Lamott, Saifullah Saifullah, Nauman Riaz, Yves-Noel Weweler, Tobias Alt-Veit, Ahmad Sarmad Ali, Muhammad Armaghan Shakir, Adrian Kalwa, et al.<br/><b>Summary Source</b>: extractive+zh-llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21824v1">https://arxiv.org/abs/2602.21824v1</a><br/><b>Summary</b>: 标题：DocDjinn：基于 VLM 和手写扩散的可控合成文档生成 arXiv ID：2602.21824 摘要：我们提出了 DocDjinn，这是一种利用视觉 - 语言模型（VLMs）的可控合成文档生成新框架，能够从未标记的种子样本生成标注文档。据我们所知，这是首项证明 VLMs 能够规模化生成高保真标注文档数据集的工作……</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">133. Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21814</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CL<br/><b>Authors</b>: Heejin Jo<br/><b>Summary Source</b>: extractive+zh-llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21814v1">https://arxiv.org/abs/2602.21814v1</a><br/><b>Summary</b>: 标题：提示架构决定推理质量：“洗车问题”的变量隔离研究 arXiv ID: 2602.21814 摘要：大语言模型始终无法解决“洗车问题”，这是一种需要隐式物理约束推理的流行推理基准。这些结果表明，结构化推理支架——特别是推理前的强制目标阐述——比上下文注入更为重要，对于...</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">134. DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21788</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Yifan Niu, Han Xiao, Dongyi Liu, Wei Zhou, Jia Li<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21788v1">https://arxiv.org/abs/2602.21788v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM）训练中因数据异构导致静态并行策略存在负载失衡与通信冗余的问题，本文提出了动态混合并行（DHP）方法，通过自适应调整通信组及并行度以毫秒级开销生成近优策略。实验结果表明，DHP 在大规模 NPU 集群上实现了最高 1.36 倍的训练吞吐量提升，显著提升了大型语言模型与多模态大语言模型的扩展性及硬件效率，优于现有的 Megatron-LM 和 DeepSpeed 框架。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">135. Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21783</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Beatrice Luciani, Alex van den Berg, Matti Lang, Alexandre L. Ratschat, Laura Marchal-Crespo<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21783v1">https://arxiv.org/abs/2602.21783v1</a><br/><b>Summary</b>: 针对机器人辅助运动中治疗师与患者交互非直观的问题，本研究提出了一种集成远程触觉控制与**大语言模型**（large language model）语音分析的交互系统，支持治疗师通过手持设备远程引导患者外骨骼。实验结果表明，相较于视觉演示，该触觉方法显著降低了任务完成时间并提升了动作平滑度，同时利用大语言模型分析揭示了更少的口头指令需求，验证了远程人机物理交互的可行性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">136. Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21779</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Zheyuan Gu, Qingsong Zhao, Yusong Wang, Zhaohong Huang, Xinqi Li, Cheng Yuan, Jiaowei Shao, Chi Zhang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21779v1">https://arxiv.org/abs/2602.21779v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（VLM）难以识别视频深度伪造中时间不一致性的问题，本文提出了法医问答（FAQ）基准，利用多模态大语言模型通过多层次任务分析动态伪影。研究构建了 FAQ-IT 指令微调集，实验表明经此训练的模型显著提升了在域内及跨数据集上的检测性能，有效验证了该基准对增强 VLM 时间推理能力的关键作用。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">137. Generalisation of RLHF under Reward Shift and Clipped KL Regularisation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21765</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Kenton Tang, Yuzhu Chen, Fengxiang He<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21765v1">https://arxiv.org/abs/2602.21765v1</a><br/><b>Summary</b>: 针对大语言模型中强化学习人类反馈（RLHF）在奖励偏移和截断 KL 正则化下的泛化性理论不足问题，本文建立了显式考虑这些因素的泛化理论框架。通过推导泛化界限，研究量化了采样误差、奖励偏移误差及 KL 裁剪误差的影响，并讨论了参数初始化和 SGD 优化的特殊情况。该理论成果为大语言模型的 KL 阈值设定及数据预算分配提供了关键指导。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">138. Offline Reasoning for Efficient Recommendation: LLM-Empowered Persona-Profiled Item Indexing</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21756</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Deogyong Kim, Junseong Lee, Jeongeun Lee, Changhoe Kim, Junguel Lee, Jungseok Lee, Dongha Lee<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21756v1">https://arxiv.org/abs/2602.21756v1</a><br/><b>Summary</b>: 针对现有基于 large language model 的推荐系统因在线推理导致高延迟的问题，本文提出 Persona4Rec 框架。该方法利用 large language model 在离线阶段构建可解释的物品画像索引，将用户匹配转化为轻量级的用户 - 画像相关性计算。实验表明，该方案在显著降低推理时间的同时保持了与 LLM 重排序器相当的性能，并提供了直观的解释。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">139. From Words to Amino Acids: Does the Curse of Depth Persist?</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21750</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Aleena Siji, Amir Mohammad Karimi Mamaghan, Ferdinand Kapl, Tobias Höppe, Emmanouil Angelis, Andrea Dittadi, Maurice Brenner, Michael Heinzinger, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21750v1">https://arxiv.org/abs/2602.21750v1</a><br/><b>Summary</b>: 本研究探究了蛋白质语言模型（PLM）是否像**大语言模型**（LLM）一样存在“深度诅咒”导致的效率低下问题。通过对六种涵盖**多模态**输入及不同训练目标的模型进行探测与扰动分析，发现其深层网络同样表现出后期层贡献递减的模式。这一发现揭示了 PLM 中的深度低效性，为未来设计更高效的架构提供了重要依据。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">140. TranX-Adapter: Bridging Artifacts and Semantics within MLLMs for Robust AI-generated Image Detection</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21716</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Wenbin Wang, Yuge Huang, Jianqing Xu, Yue Yu, Jiangtao Yan, Shouhong Ding, Pan Zhou, Yong Luo<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21716v1">https://arxiv.org/abs/2602.21716v1</a><br/><b>Summary</b>: 针对**multimodal large language model (MLLM)** 在 AI 生成图像检测中因伪影特征相似性导致注意力稀释的问题，本文提出了 TranX-Adapter 适配器。该方法通过任务感知最优传输与交叉注意力机制，实现**vision language model (VLM)** 内语义与伪影信息的高效双向迁移。实验显示，该方案在多个基准测试中将检测准确率提升高达 6%，显著增强了**large language model**的鲁棒性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">141. SurGo-R1: Benchmarking and Modeling Contextual Reasoning for Operative Zone in Surgical Video</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21706</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Guanyi Qin, Xiaozhen Wang, Zhu Zhuo, Chang Han Low, Yuancan Xiao, Yibing Fu, Haofeng Liu, Kai Wang, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21706v1">https://arxiv.org/abs/2602.21706v1</a><br/><b>Summary</b>: 针对现有视觉语言模型（VLM）在微创手术中难以处理依赖阶段的安全区域推理问题，本文构建了 ResGo 基准并提出 SurGo-R1 模型。SurGo-R1 通过强化学习优化多模态大语言模型，采用“先识别手术阶段后生成坐标”的架构，在未见手术数据上相比主流通用 VLM 提升了 6.6 倍的性能。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">142. Dynamic Multimodal Activation Steering for Hallucination Mitigation in Large Vision-Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21704</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Jianghao Yin, Qin Chen, Kedi Chen, Jie Zhou, Xingjiao Wu, Liang He<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21704v1">https://arxiv.org/abs/2602.21704v1</a><br/><b>Summary</b>: 针对大视觉语言模型（Vision Language Model）普遍存在的幻觉问题，本文提出了一种无需训练的动态多模态激活引导方法。该方法通过构建语义真实性引导向量库，在推理阶段根据输入上下文动态干预注意力头，显著提升了多模态大语言模型（Multimodal Large Language Model）的性能，效果优于现有最先进方法。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">143. Breaking Semantic-Aware Watermarks via LLM-Guided Coherence-Preserving Semantic Injection</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21593</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV, cs.LG<br/><b>Authors</b>: Zheng Gao, Xiaoyu Li, Zhicheng Bao, Xiaoyan Feng, Jiaojiao Jiang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21593v1">https://arxiv.org/abs/2602.21593v1</a><br/><b>Summary</b>: 当前扩散模型中的语义水印方案易受**大型语言模型**（LLM）利用结构化推理进行的局部微调且全局相干的语义篡改攻击，暴露了现有**多模态大语言模型**相关设计的脆弱性。为此，我们提出了相干性保持语义注入（CSI）方法，借助**大语言模型**引导在嵌入空间约束下选择性扰动水印相关语义，实验证明其能有效绕过内容感知水印检测并揭示根本性安全弱点。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">144. Revisiting RAG Retrievers: An Information Theoretic Benchmark</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21553</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Wenqing Zheng, Dmitri Kalaev, Noah Fatsi, Daniel Barcklow, Owen Reinert, Igor Melnyk, Senthil Kumar, C. Bayan Bruss<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21553v1">https://arxiv.org/abs/2602.21553v1</a><br/><b>Summary</b>: 针对现有检索增强生成（RAG）基准缺乏对检索器机制系统性理解的问题，本文提出了基于信息论的 MIGRASCOPE 分析框架。该方法利用互信息度量量化检索质量与冗余，揭示了不同检索策略在大型语言模型中的互补性与协同效应。研究证明精心选择的检索器集成优于单一方案，为构建高效 RAG 系统提供了理论依据与实践指导。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">145. Reasoning-Driven Design of Single Atom Catalysts via a Multi-Agent Large Language Model Framework</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21533</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Dong Hyeon Mok, Seoin Back, Victor Fung, Guoxiang Hu<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21533v1">https://arxiv.org/abs/2602.21533v1</a><br/><b>Summary</b>: 针对传统材料发现方法缺乏推理能力的问题，本文提出了基于多智能体**大语言模型**的 MAESTRO 框架，通过多角色协作与迭代优化自主设计单原子催化剂。该研究利用**大语言模型**的上下文学习能力挖掘隐含设计原则，成功发现突破传统标度关系的高性能催化剂，验证了多智能体**大语言模型**框架在生成化学洞察方面的潜力。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">146. See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21497</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Yongchang Zhang, Xianzheng Ma, Tianyi Liu, Guangquan Zhou, Yang Chen<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21497v1">https://arxiv.org/abs/2602.21497v1</a><br/><b>Summary</b>: 针对 vision language model 在链式思维推理中易受视觉幻觉传播影响的问题，本文提出了一种轻量级、无需训练的迭代框架来增强 multimodal large language model 的视觉 grounding 能力。该方法通过构建动态视觉证据池，确保 large language model 生成的每个 token 均得到图像证据支持，从而避免了昂贵的强化学习微调。实验表明，该 VLM 方案显著降低了幻觉率并提升了推理准确率，实现了跨架构的即插即用优化。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">147. GradAlign: Gradient-Aligned Data Selection for LLM Reinforcement Learning</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21492</code> | <b>Published</b>: 2026-02-25<br/><b>Matched Categories</b>: cs.LG<br/><b>Authors</b>: Ningyuan Yang, Weihua Du, Weiwei Sun, Sean Welleck, Yiming Yang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21492v1">https://arxiv.org/abs/2602.21492v1</a><br/><b>Summary</b>: 针对大语言模型强化学习中因策略非平稳性导致的数据质量敏感问题，现有方法常依赖低效的启发式筛选。本文提出 GradAlign，利用小规模验证集进行梯度对齐以优先选择高价值训练问题，从而构建自适应课程。该方法在多种挑战性数据场景下显著优于基线，证明了方向性梯度信号对优化大语言模型训练稳定性和性能的重要性。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">148. Causal Decoding for Hallucination-Resistant Multimodal Large Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21441</code> | <b>Published</b>: 2026-02-24<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Shiwei Tan, Hengyi Wang, Weiyi Qin, Qi Xu, Zhigang Hua, Hao Wang<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21441v1">https://arxiv.org/abs/2602.21441v1</a><br/><b>Summary</b>: 针对多模态大语言模型（MLLM/VLM）在视觉语言任务中易产生物体幻觉的问题，本文提出了一种因果解码框架，通过在生成过程中施加针对性因果干预来重塑解码动态。该方法有效抑制了虚假对象令牌的依赖，在保持描述质量的同时显著降低了幻觉率，并在基准测试中实现了最先进的忠实度表现。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">149. Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21435</code> | <b>Published</b>: 2026-02-24<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Shengqiong Wu, Bobo Li, Xinkai Wang, Xiangtai Li, Lei Cui, Furu Wei, Shuicheng Yan, Hao Fei, et al.<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21435v1">https://arxiv.org/abs/2602.21435v1</a><br/><b>Summary</b>: 针对现有统一视觉语言模型（UVLM）中理解与生成能力缺乏协同交互的问题，本文提出了一种交错分析 - 起草思维循环（AD-Loop）方法，旨在多模态大语言模型框架下实现两者的深度融合。该方法通过动态交替文本与视觉思考，并结合监督学习与强化学习进行训练，显著提升了各类 VLM 架构在标准基准测试中的理解与生成性能。此外，该策略展现了良好的跨架构迁移能力，为多模态大语言模型的协同优化提供了有效方案。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">150. PSF-Med: Measuring and Explaining Paraphrase Sensitivity in Medical Vision Language Models</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21428</code> | <b>Published</b>: 2026-02-24<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Binesh Sadanandan, Vahid Behzadan<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21428v1">https://arxiv.org/abs/2602.21428v1</a><br/><b>Summary</b>: 医学视觉语言模型（VLM）在面对问题重述时出现答案不一致，给临床部署带来风险。本文构建 PSF-Med 基准，利用稀疏自编码器在多模态大语言模型中定位关键 latent token，揭示了大型语言模型组件对提示敏感性的机制。实验表明，钳制该 latent token 可显著降低翻转率并减少文本先验依赖，强调评估需兼顾重述稳定性与图像依赖。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">151. Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21406</code> | <b>Published</b>: 2026-02-24<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Asim Unmesh, Kaki Ramesh, Mayank Patel, Rahul Jain, Karthik Ramani<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21406v1">https://arxiv.org/abs/2602.21406v1</a><br/><b>Summary</b>: 针对传统时序动作分割受限于封闭词汇的问题，本文提出利用视觉语言模型（Vision Language Model）实现开放词汇零样本动作分割，并通过无训练流水线结合帧 - 动作嵌入与相似度矩阵进行推理。该方法有效挖掘了多模态大语言模型的零样本能力，在无需特定监督下实现了高质量的动作分段，并系统评估了 14 种模型以提供广泛基准。</div>
</div>

<div style="margin-top:14px;border:1px solid #bfdbfe;border-radius:14px;padding:14px 16px;background:linear-gradient(165deg,#eff6ff,#ecfeff);">
<div style="font-size:18px;font-weight:700;color:#1e3a8a;margin-bottom:8px;">152. MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation</div>
<div style="line-height:1.75;color:#0f172a;"><b>arXiv ID</b>: <code>2602.21397</code> | <b>Published</b>: 2026-02-24<br/><b>Matched Categories</b>: cs.CV<br/><b>Authors</b>: Sajjad Ghiasvand, Haniyeh Ehsani Oskouie, Mahnoosh Alizadeh, Ramtin Pedarsani<br/><b>Summary Source</b>: llm<br/><b>Link</b>: <a href="https://arxiv.org/abs/2602.21397v1">https://arxiv.org/abs/2602.21397v1</a><br/><b>Summary</b>: 针对视觉语言模型（Vision Language Model）和多模态大语言模型（Multimodal Large Language Model）适配中提示学习参数效率低的问题，本文提出 MMLoP 框架。该方法利用低秩因子化构建高效潜在令牌（latent token），将可训练参数量压缩至 11.5K 并通过一致性损失增强跨模态对齐。实验表明，MMLoP 在 VLM 下游任务中实现了显著的精度 - 效率权衡，优于多数参数量级更大的现有方法。</div>
</div>
